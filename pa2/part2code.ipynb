{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim import Adam, SGD\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from torchtext import *\n",
    "from torchtext.data import *\n",
    "\n",
    "import nltk\n",
    "#nltk.download('punkt')\n",
    "from nltk import word_tokenize\n",
    "\n",
    "txt_field = data.Field(tokenize=word_tokenize, lower=True, include_lengths=True, batch_first=True)\n",
    "label_field = data.Field(sequential=False, use_vocab=False, batch_first=True)\n",
    "\n",
    "# make splits for data\n",
    "train, test= TabularDataset.splits(path='./', train='train.csv', test='test.csv',format='csv', \n",
    "                                  fields=[('label', label_field),('sentence', txt_field)], skip_header=True)\n",
    "\n",
    "txt_field.build_vocab(train, min_freq=5)\n",
    "train_iter, test_iter = data.BucketIterator.splits((train, test), batch_size=32, \n",
    "                                                   sort_key=lambda x: len(x.sentence),sort_within_batch=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 40000\n",
      "Number of testing samples: 3000\n",
      "Unique tokens in TEXT vocabulary: 38331\n",
      "Example of training data:\n",
      " {'label': '1', 'sentence': ['i', 'guess', 'those', 'who', 'have', 'been', 'in', 'a', 'one-sided', 'relationship', 'of', 'some', 'sort', 'before', 'will', 'be', 'able', 'identify', 'with', 'the', 'lead', 'character', 'minako', 'yuko', 'tanaka', ',', 'a', '50', 'year', 'old', 'woman', 'who', 'is', 'still', 'in', 'the', 'pink', 'of', 'good', 'health', ',', 'as', 'demonstrated', 'by', 'her', 'daily', ',', 'grinding', 'routine', 'of', 'waking', 'up', 'extremely', 'early', 'in', 'the', 'morning', 'to', 'prepare', 'for', 'her', 'milk', 'delivery', 'work', ',', 'where', 'she', 'has', 'to', 'lug', 'bottles', 'of', 'megmilk', 'in', 'a', 'bag', 'in', 'a', 'route', 'around', 'her', 'town', 'like', 'clockwork', ',', 'to', 'exchange', 'empty', 'bottles', 'for', 'full', 'ones', ',', 'and', 'to', 'collect', 'payment', 'and', 'issue', 'receipt', '.', 'and', 'there', \"'s\", 'always', 'be', 'that', 'one', 'delivery', 'stop', 'that', \"'s\", 'right', 'at', 'the', 'top', ',', 'needing', 'to', 'scale', 'a', 'long', 'flight', 'of', 'stairs', 'in', 'order', 'to', 'achieve', 'customer', 'satisfaction', '.', 'and', 'peculiar', 'enough', ',', 'that', 'stop', 'happened', 'to', 'be', 'a', 'stop', 'delivering', 'to', 'a', 'man', 'with', 'whom', 'she', 'has', 'been', 'in', 'love', 'with', 'for', 'almost', 'all', 'her', 'teenage', 'to', 'adult', 'life', ',', 'and', 'not', 'having', 'the', 'product', 'appreciated', ',', 'but', 'poured', 'down', 'the', 'sink', '.', 'having', 'gone', 'to', 'the', 'same', 'school', ',', 'we', 'see', 'that', 'they', \"'re\", 'not', 'talking', 'to', 'each', 'other', ',', 'and', 'in', 'their', 'daily', 'life', 'always', 'seem', 'so', 'close', 'physically', ',', 'but', 'yet', 'so', 'far', 'away', '.', 'there', \"'s\", 'no', 'eye', 'contact', ',', 'save', 'for', 'cursory', 'glances', 'by', 'chance', ',', 'and', 'little', 'acknowledgement', 'of', 'each', 'other', \"'s\", 'existence', '.', 'we', 'learn', 'that', 'they', 'share', 'a', 'past', 'that', 'probably', 'destroyed', 'all', 'notions', 'of', 'being', 'together', ',', 'where', 'clear', 'attraction', 'between', 'the', 'two', 'was', 'hampered', 'from', 'developing', 'further', 'by', 'the', 'earlier', 'generation', '.', 'while', 'i', 'thought', 'minako', 'was', 'an', 'interesting', 'woman', 'in', 'herself', ',', 'one', 'who', 'has', 'kept', 'her', 'feelings', 'suppressed', 'for', 'so', 'long', ',', 'one', 'can', 'only', 'wonder', 'what', 'kind', 'of', 'damage', 'it', 'would', 'do', '.', 'if', 'i', 'read', 'that', 'the', 'original', 'japanese', 'title', 'means', 'at', 'some', 'time', 'the', 'days', 'you', 'read', 'books', 'and', 'it', \"'s\", 'accurate', ',', 'i', 'felt', 'the', 'movie', 'had', 'a', 'wonderful', 'finale', 'with', 'that', 'shot', 'of', 'her', 'well', 'stocked', 'bookcase', ',', 'likely', 'alluding', 'to', 'the', 'fact', 'that', 'she', \"'s\", 'not', 'alone', 'after', 'all', ',', 'and', 'had', 'probably', 'fallen', 'back', 'on', 'her', 'crutch', 'of', 'sorts', 'to', 'deal', 'with', 'the', 'pain', 'of', 'being', 'alone', ',', 'and', 'back', 'to', 'a', 'lifestyle', 'which', 'she', 'had', 'already', 'been', 'accustomed', 'to', 'for', '50', 'years', '.', 'besides', 'immersing', 'herself', 'in', 'two', 'jobs', ',', 'she', 'has', 'those', 'books', 'which', 'serve', 'as', 'a', 'form', 'of', 'escapism', ',', 'and', 'occasionally', 'pens', 'little', 'sweet', 'nothings', 'to', 'song', 'dedication', 'shows', 'on', 'the', 'radio', '.', 'yuko', 'tanaka', 'did', 'a', 'commendable', 'job', 'as', 'the', 'emotionally', 'strong', 'woman', 'resigned', 'to', 'her', 'fate', 'and', 'her', 'decision', 'to', 'love', 'none', 'other', ',', 'her', 'object', 'of', 'affection', ',', 'takanashi', 'ittoku', 'kishibe', 'was', 'a', 'more', 'interesting', 'character', 'who', 'has', 'more', 'facets', '.', 'staying', 'true', 'to', 'marriage', 'vows', ',', 'he', 'spends', 'significant', 'amount', 'of', 'screen', 'time', 'looking', 'after', 'his', 'sickly', 'bedridden', 'wife', 'played', 'by', 'akiko', 'nishina', ',', 'while', 'juggling', 'with', 'his', 'job', 'of', 'social', 'welfare', 'in', 'the', 'children', \"'s\", 'affairs', 'department', 'in', 'city', 'hall', '.', 'i', 'felt', 'that', 'as', 'a', 'childless', 'couple', ',', 'the', 'job', 'provided', 'him', 'a', 'means', 'to', 'care', ',', 'not', 'for', 'his', 'own', ',', 'but', 'for', 'other', 'people', \"'s\", 'children', ',', 'the', 'troubled', 'ones', 'who', 'are', 'neglected', 'and', 'left', 'to', 'fend', 'for', 'themselves', '.', 'in', 'a', 'rare', 'moment', 'of', 'rage', ',', 'we', 'see', 'how', 'he', 'angrily', 'chides', 'such', 'wayward', 'parents', 'who', 'do', \"n't\", 'appreciate', 'and', 'wastes', 'their', 'children', \"'s\", 'lives', 'away', '.', 'the', 'story', 'by', 'kenji', 'aoki', 'provides', 'little', 'quirks', 'to', 'make', 'its', 'characters', 'appeal', 'and', 'successfully', 'attempted', 'to', 'provide', 'a', 'lot', 'more', 'glimpses', 'and', 'dimension', 'into', 'them', 'as', 'well', ',', 'such', 'as', 'how', 'takanashi', 'is', 'a', 'hopeless', 'haiku', 'poet', 'despite', 'being', 'a', 'member', 'of', 'the', 'haiku', 'club', ',', 'and', 'supporting', 'characters', 'such', 'as', 'the', 'aged', 'minagawa', 'couple', ',', 'where', 'masao', 'koichi', 'ueda', 'lent', 'some', 'comical', 'though', 'sad', 'moments', 'as', 'he', 'slowly', 'turned', 'senile', ',', 'while', 'wife', 'toshiko', 'misako', 'watanabe', 'narrates', 'and', 'brings', 'us', 'through', 'this', 'love', 'story', 'of', 'a', 'single', 'woman', 'at', '50', '.', 'even', 'akiko', 'nishina', \"'s\", 'performance', 'as', 'the', 'bedridden', 'wife', 'was', 'nothing', 'short', 'of', 'arresting', ',', 'with', 'her', 'character', \"'s\", 'enlightened', 'state', 'of', 'knowing', 'her', 'husband', \"'s\", 'past', ',', 'and', 'making', 'unselfish', ',', 'and', 'painful', 'decisions', 'in', 'her', 'sickly', 'state', '.', 'it', \"'s\", 'what', 'you', 'can', 'expect', 'from', 'a', 'typical', 'japanese', 'romantic', 'movie', ',', 'sans', 'young', ',', 'nubile', 'leads', 'as', 'star-crossed', 'lovers', ',', 'but', 'with', 'all', 'other', 'elements', 'in', 'place', 'such', 'as', 'romantic', 'set', 'ups', ',', 'love', 'songs', 'and', 'those', 'quintessential', 'restrained', 'but', 'affectionate', 'behaviour', '.', 'i', 'thought', 'the', 'story', 'was', 'in', 'danger', 'of', 'going', 'down', 'the', 'beaten', 'track', 'when', 'unrequited', 'love', 'gets', 'consummated', ',', 'but', 'director', 'akira', 'ogata', 'managed', 'to', 'steer', 'clear', 'of', 'the', 'usual', 'melodramatic', 'moments', 'in', 'such', 'stories', ',', 'though', 'the', 'story', 'did', 'call', 'for', 'some', 'obvious', 'plot', 'development', 'into', 'the', 'final', 'act', 'that', 'you', 'can', 'predict', ',', 'especially', 'if', 'you', \"'re\", 'already', 'way', 'past', 'your', 'romance', 'movie', '101', '.', 'not', 'being', 'your', 'average', 'lovey-dovey', 'story', ',', 'i', 'thought', 'the', 'milkwoman', 'told', 'a', 'strong', 'story', 'with', 'unrequited', 'love', 'as', 'a', 'central', 'theme', ',', 'and', 'frankly', 'a', 'recommended', 'romance', 'movie', 'though', 'told', 'at', 'a', 'measured', 'pace', 'if', 'you', \"'re\", 'in', 'the', 'mood', 'for', 'some', 'bittersweet', 'loving', ',', 'reminiscence', ',', 'and', 'seeking', 'to', 'live', 'without', 'regrets', '.']}\n",
      "\n",
      "Example of testing data:\n",
      " {'label': '0', 'sentence': ['almost', 'from', 'the', 'word', 'go', 'this', 'film', 'is', 'poor', 'and', 'lacking', 'conviction', 'but', 'then', 'again', 'most', 'people', 'would', 'struggle', 'to', 'show', 'commitment', 'to', 'a', 'script', 'as', 'uninspiring', 'as', 'this', '.', 'the', 'dialogue', 'really', 'does', 'not', 'flow', 'and', 'sometimes', 'as', 'in', 'this', 'case', 'more', 'is', 'less', 'or', 'should', 'have', 'been', '.', 'this', 'is', 'also', 'backed-up', 'by', 'odd', 'scenes', 'e.g', '.', 'the', 'cemetry', 'slow-motion', 'walk', 'that', 'you', 'think', 'might', 'lead', 'somewhere', 'but', 'only', 'seem', 'to', 'waste', 'a', 'few', 'more', 'seconds', 'of', 'your', 'life', '.', 'the', 'plot', 'is', 'a', 'strange', 'combination', 'of', 'gangster', 'situation', 'comedy', 'which', 'i', 'am', 'sure', 'seemed', 'a', 'good', 'idea', 'at', 'the', 'time', 'but', 'if', 'ever', 'there', 'was', 'a', 'case', 'for', 'someone', 'needing', 'to', 'be', 'honest', 'with', 'the', 'scriptwriter', 'then', 'here', 'was', 'it', '.', 'martin', 'freeman', 'is', 'okay', 'but', 'then', 'he', 'seems', 'to', 'have', 'one', 'character', 'which', 'always', 'plays', 'so', 'i', 'am', 'beginning', 'to', 'wonder', 'if', 'he', 'was', 'given', 'a', 'script', 'or', 'just', 'filmed', 'and', 'told', 'to', 'react', 'as', 'normal', '.', 'finally', '-', 'humour', '.', 'this', 'reminds', 'me', 'of', 'the', \"'python\", 'i', 'think', 'quote', 'about', 'shakespere', ',', 'of', 'his', \"'comedies\", \"'\", '-', 'if', 'he', 'had', 'meant', 'it', 'to', 'be', 'humorous', 'he', 'would', 'have', 'put', 'a', 'joke', 'in', 'it', '.', 'well', 'i', 'did', \"n't\", 'see', 'one', '.', 'do', \"n't\", 'waste', 'your', 'time', '-', 'i', 'did', 'because', 'i', 'was', 'watching', 'it', 'with', 'a', 'friend', 'and', 'kept', 'hoping', 'that', 'it', 'was', 'going', 'to', 'get', 'better', '.', 'it', 'did', \"n't\", '.']}\n",
      "\n",
      "label tensor torch.Size([30])\n",
      "tensor([0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1,\n",
      "        1, 1, 0, 0, 0, 0])\n",
      "\n",
      "sentence length tensor torch.Size([30])\n",
      "tensor([177, 177, 177, 177, 177, 177, 177, 177, 176, 176, 176, 176, 176, 176,\n",
      "        176, 176, 176, 176, 176, 176, 176, 175, 175, 175, 175, 175, 175, 175,\n",
      "        175, 175])\n",
      "\n",
      "sentence tensor torch.Size([30, 177])\n",
      "tensor([[  50,   23,  329,  ...,  174,  131,    4],\n",
      "        [  13,   20,    9,  ...,  416,   60,    4],\n",
      "        [ 251,    3,  427,  ...,  558, 1117,   33],\n",
      "        ...,\n",
      "        [  12,  187,   13,  ...,    4,    1,    1],\n",
      "        [  12,  295,   13,  ...,    4,    1,    1],\n",
      "        [ 957,   64,  663,  ...,    4,    1,    1]])\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of training samples: {len(train.examples)}')\n",
    "print(f'Number of testing samples: {len(test.examples)}')\n",
    "print(f\"Unique tokens in TEXT vocabulary: {len(txt_field.vocab)}\")\n",
    "print(f'Example of training data:\\n {vars(train.examples[0])}\\n')\n",
    "print(f'Example of testing data:\\n {vars(test.examples[1])}\\n')\n",
    "\n",
    "_,batch  = next(enumerate(train_iter))\n",
    "print('label tensor', batch.label.shape)\n",
    "print(batch.label)\n",
    "print()\n",
    "sent, sent_len = batch.sentence\n",
    "print('sentence length tensor', sent_len.shape)\n",
    "print(sent_len)\n",
    "print()\n",
    "print('sentence tensor', sent.shape)\n",
    "print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Text_RNN(nn.Module):\n",
    "    def __init__(self, n_vocab, embedding_dim, n_hidden, n_layers, dropout, output_size):\n",
    "        super(Text_RNN, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.n_hidden = n_hidden\n",
    "        self.emb = nn.Embedding(n_vocab, embedding_dim)\n",
    "        self.rnn = nn.RNN(\n",
    "                input_size=embedding_dim,\n",
    "                hidden_size=n_hidden,\n",
    "                num_layers=n_layers,\n",
    "                dropout=dropout,\n",
    "                batch_first=True\n",
    "        )\n",
    "        self.dropout=nn.Dropout(dropout)\n",
    "        self.fc=nn.Linear(n_hidden, output_size)\n",
    "        self.sigmoid=nn.Sigmoid()\n",
    "    def forward(self, sent, sent_len):\n",
    "        # sent: batch_size, max_sent_len\n",
    "        # sent_len: batch_size\n",
    "        \n",
    "        sent_emb = self.emb(sent)  #batch_size, max_sent_len, embedding_dim\n",
    "        \n",
    "        # method 1\n",
    "        #outputs, hidden = self.rnn(sent_emb)\n",
    "        \n",
    "        # method 2, pack the input sequence, more computationally efficient\n",
    "        packed_embedded = nn.utils.rnn.pack_padded_sequence(sent_emb, src_len, batch_first=True)\n",
    "        packed_outputs, hidden = self.rnn(packed_embedded)\n",
    "        outputs, _ = torch.nn.utils.rnn.pad_packed_sequence(packed_outputs, batch_first=True)\n",
    "        \n",
    "        #output: batch_size, max_sent_len, n_hidden\n",
    "        #hidden: n_layer, batch_size, n_hidden \n",
    "        prob = self.dropout(hidden[-1,:,:])\n",
    "        prob = torch.sigmoid(self.fc(prob))\n",
    "        return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(save_path, model, optimizer, val_loss):\n",
    "    if save_path==None:\n",
    "        return\n",
    "    save_path = save_path \n",
    "    state_dict = {'model_state_dict': model.state_dict(),\n",
    "                  'optimizer_state_dict': optimizer.state_dict(),\n",
    "                  'val_loss': val_loss}\n",
    "\n",
    "    torch.save(state_dict, save_path)\n",
    "\n",
    "    print(f'Model saved to ==> {save_path}')\n",
    "\n",
    "def load_checkpoint(model, optimizer, save_path):\n",
    "    state_dict = torch.load(save_path)\n",
    "    model.load_state_dict(state_dict['model_state_dict'])\n",
    "    optimizer.load_state_dict(state_dict['optimizer_state_dict'])\n",
    "    val_loss = state_dict['val_loss']\n",
    "    print(f'Model loaded from <== {save_path}')\n",
    "    \n",
    "    return val_loss\n",
    "\n",
    "\n",
    "def TRAIN(model, train_loader, valid_loader,  num_epochs, eval_every, total_step, criterion, optimizer, val_loss, device, save_name):\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    global_step = 0\n",
    "    if val_loss==None:\n",
    "        best_val_loss = float(\"Inf\")  \n",
    "    else: \n",
    "        best_val_loss=val_loss\n",
    "    \n",
    "    model.to(device)\n",
    "    for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "\n",
    "        for i, (_,batch) in enumerate(train_loader):\n",
    "            \n",
    "            model.train()\n",
    "            batch = batch.to(device)\n",
    "            text, text_lengths = batch.sentence\n",
    "            labels = batch.label\n",
    "            '''Training of the model'''\n",
    "            # Forward pass\n",
    "            outputs = model(text, text_lengths)\n",
    "            rounded_preds = torch.round(outputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            global_step += 1\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            '''Evaluating the model every x steps'''\n",
    "            if global_step % eval_every == 0:\n",
    "                with torch.no_grad():\n",
    "                    model.eval()\n",
    "                    val_running_loss = 0.0\n",
    "                    for _,val_batch in valid_loader:\n",
    "                        val_text, val_lengths = val_batch.sentence\n",
    "                        val_labels = val_batch.label\n",
    "                        val_outputs = model(val_text, val_lengths)\n",
    "                        val_loss = criterion(val_outputs, val_labels)\n",
    "                        val_running_loss += val_loss.item()\n",
    "\n",
    "                    average_train_loss = running_loss / eval_every\n",
    "                    average_val_loss = val_running_loss / len(valid_loader)\n",
    "\n",
    "                    print('Epoch [{}/{}], Step [{}/{}], Train Loss: {:.4f}, Valid Loss: {:.4f}' \n",
    "                          .format(epoch+1, num_epochs, global_step, total_step, average_train_loss, average_val_loss))\n",
    "\n",
    "                    running_loss = 0.0\n",
    "                    if average_val_loss < best_val_loss:\n",
    "                        best_val_loss = average_val_loss\n",
    "                        save_checkpoint(save_name, model, optimizer, best_val_loss)\n",
    "                    \n",
    "    print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at ..\\c10\\core\\CPUAllocator.cpp:72] data. DefaultCPUAllocator: not enough memory: you tried to allocate 5877062244 bytes. Buy new RAM!\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-f9cd4993c43b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# build model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBCELoss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mText_RNN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_vocab\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_vocab\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0membedding_dim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0membedding_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_hidden\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_hidden\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_layers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_layers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_size\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0moutput_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-c727565950e8>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, n_vocab, embedding_dim, n_hidden, n_layers, dropout, output_size)\u001b[0m\n\u001b[0;32m     10\u001b[0m                 \u001b[0mnum_layers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_layers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m                 \u001b[0mdropout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m                 \u001b[0mbatch_first\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m         )\n\u001b[0;32m     14\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    382\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Unknown nonlinearity '{}'\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnonlinearity\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 384\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    385\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, mode, input_size, hidden_size, num_layers, bias, batch_first, dropout, bidirectional)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m                 \u001b[0mw_ih\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mParameter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgate_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayer_input_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m                 \u001b[0mw_hh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mParameter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgate_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m                 \u001b[0mb_ih\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mParameter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgate_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m                 \u001b[1;31m# Second bias vector included for CuDNN compatibility. Only one\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: [enforce fail at ..\\c10\\core\\CPUAllocator.cpp:72] data. DefaultCPUAllocator: not enough memory: you tried to allocate 5877062244 bytes. Buy new RAM!\n"
     ]
    }
   ],
   "source": [
    "device ='cpu'\n",
    "# define parameters\n",
    "n_vocab = len(txt_field.vocab)\n",
    "embedding_dim = 64\n",
    "n_hidden=128\n",
    "n_layers=2\n",
    "dropout = 0.5\n",
    "lr = 0.001\n",
    "output_size = 1\n",
    "# build model\n",
    "criterion = nn.BCELoss()\n",
    "model = Text_RNN(n_vocab=n_vocab, embedding_dim=embedding_dim, n_hidden=n_hidden, n_layers=n_layers, dropout=dropout, output_size =output_size).to(device)\n",
    "optimizer = Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
