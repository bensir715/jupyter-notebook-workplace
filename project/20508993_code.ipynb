{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 146
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 20883,
     "status": "ok",
     "timestamp": 1589722742216,
     "user": {
      "displayName": "Hoshi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgvJ9tk-7YVwMuT4roRhSvIVbF7D-gcIePVxYIukw=s64",
      "userId": "16228246563220513239"
     },
     "user_tz": -480
    },
    "id": "r8vPlGEYTYM5",
    "outputId": "db1b30cf-7371-4bdd-8097-863e04bc3942"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /gdrive\n",
      "/gdrive/.shortcut-targets-by-id/1RRusJqm7Xt1QJlcIE4OP4kkqoum4BW4V/COMP4211_Colab\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/gdrive')\n",
    "%cd /gdrive/My Drive/COMP4211_Colab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j2Rtt8f8Dw4L"
   },
   "source": [
    "# **COMP4211 Project**\n",
    "**Logistic Regression To Predict Heart Disease Prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-eQ7D4HqUPWq"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import math\n",
    "import warnings\n",
    "import pickle\n",
    "import scipy.special\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pylab import rcParams\n",
    "from time import time\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler  # Preprocessing\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, SGDClassifier, Perceptron # Trainin\n",
    "from sklearn import svm\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV, learning_curve, validation_curve, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, f1_score, plot_confusion_matrix, confusion_matrix, classification_report, mean_squared_error, r2_score # Stopping Metrics\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from sklearn.utils.fixes import loguniform\n",
    "from matplotlib.colors import ListedColormap\n",
    "from matplotlib.ticker import NullFormatter\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader  # Preprocessing\n",
    "from torch.utils.data import random_split\n",
    "from torch.optim import Adam, SGD # Training\n",
    "from torch.utils.tensorboard import SummaryWriter  # Stopping Metrics\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XudT5z8CGin7"
   },
   "source": [
    "## **Data Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 646
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2718,
     "status": "ok",
     "timestamp": 1589722750145,
     "user": {
      "displayName": "Hoshi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgvJ9tk-7YVwMuT4roRhSvIVbF7D-gcIePVxYIukw=s64",
      "userId": "16228246563220513239"
     },
     "user_tz": -480
    },
    "id": "-33-ZV7BWPmV",
    "outputId": "6d280b91-4121-4184-a539-1a50e8c80a3f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>male</th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>currentSmoker</th>\n",
       "      <th>cigsPerDay</th>\n",
       "      <th>BPMeds</th>\n",
       "      <th>prevalentStroke</th>\n",
       "      <th>prevalentHyp</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>totChol</th>\n",
       "      <th>sysBP</th>\n",
       "      <th>diaBP</th>\n",
       "      <th>BMI</th>\n",
       "      <th>heartRate</th>\n",
       "      <th>glucose</th>\n",
       "      <th>TenYearCHD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>26.97</td>\n",
       "      <td>80.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>28.73</td>\n",
       "      <td>95.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>127.5</td>\n",
       "      <td>80.0</td>\n",
       "      <td>25.34</td>\n",
       "      <td>75.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>28.58</td>\n",
       "      <td>65.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>23.10</td>\n",
       "      <td>85.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>30.30</td>\n",
       "      <td>77.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>33.11</td>\n",
       "      <td>60.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>313.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>21.68</td>\n",
       "      <td>79.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>260.0</td>\n",
       "      <td>141.5</td>\n",
       "      <td>89.0</td>\n",
       "      <td>26.36</td>\n",
       "      <td>76.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>23.61</td>\n",
       "      <td>93.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>22.91</td>\n",
       "      <td>75.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>247.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>27.64</td>\n",
       "      <td>72.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>294.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>26.31</td>\n",
       "      <td>98.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>332.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>31.31</td>\n",
       "      <td>65.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>226.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>22.35</td>\n",
       "      <td>85.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>21.35</td>\n",
       "      <td>95.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>232.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>22.37</td>\n",
       "      <td>64.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>291.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>23.38</td>\n",
       "      <td>80.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>84.5</td>\n",
       "      <td>23.24</td>\n",
       "      <td>75.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>26.88</td>\n",
       "      <td>85.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    male  age  education  currentSmoker  ...    BMI  heartRate  glucose  TenYearCHD\n",
       "0      1   39        4.0              0  ...  26.97       80.0     77.0           0\n",
       "1      0   46        2.0              0  ...  28.73       95.0     76.0           0\n",
       "2      1   48        1.0              1  ...  25.34       75.0     70.0           0\n",
       "3      0   61        3.0              1  ...  28.58       65.0    103.0           1\n",
       "4      0   46        3.0              1  ...  23.10       85.0     85.0           0\n",
       "5      0   43        2.0              0  ...  30.30       77.0     99.0           0\n",
       "6      0   63        1.0              0  ...  33.11       60.0     85.0           1\n",
       "7      0   45        2.0              1  ...  21.68       79.0     78.0           0\n",
       "8      1   52        1.0              0  ...  26.36       76.0     79.0           0\n",
       "9      1   43        1.0              1  ...  23.61       93.0     88.0           0\n",
       "10     0   50        1.0              0  ...  22.91       75.0     76.0           0\n",
       "11     0   43        2.0              0  ...  27.64       72.0     61.0           0\n",
       "12     1   46        1.0              1  ...  26.31       98.0     64.0           0\n",
       "13     0   41        3.0              0  ...  31.31       65.0     84.0           0\n",
       "14     0   39        2.0              1  ...  22.35       85.0      NaN           0\n",
       "15     0   38        2.0              1  ...  21.35       95.0     70.0           1\n",
       "16     1   48        3.0              1  ...  22.37       64.0     72.0           0\n",
       "17     0   46        2.0              1  ...  23.38       80.0     89.0           1\n",
       "18     0   38        2.0              1  ...  23.24       75.0     78.0           0\n",
       "19     1   41        2.0              0  ...  26.88       85.0     65.0           0\n",
       "\n",
       "[20 rows x 16 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = \"./Data/framingham.csv\"\n",
    "dfo = pd.read_csv(data_path)\n",
    "dfo.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 307
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 921,
     "status": "ok",
     "timestamp": 1589722750146,
     "user": {
      "displayName": "Hoshi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgvJ9tk-7YVwMuT4roRhSvIVbF7D-gcIePVxYIukw=s64",
      "userId": "16228246563220513239"
     },
     "user_tz": -480
    },
    "id": "ndkOZyU5bqUT",
    "outputId": "f4a5dfe7-b863-49ef-b9a5-506b496f0a92"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>male</th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>currentSmoker</th>\n",
       "      <th>cigsPerDay</th>\n",
       "      <th>BPMeds</th>\n",
       "      <th>prevalentStroke</th>\n",
       "      <th>prevalentHyp</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>totChol</th>\n",
       "      <th>sysBP</th>\n",
       "      <th>diaBP</th>\n",
       "      <th>BMI</th>\n",
       "      <th>heartRate</th>\n",
       "      <th>glucose</th>\n",
       "      <th>TenYearCHD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4238.000</td>\n",
       "      <td>4238.000</td>\n",
       "      <td>4133.000</td>\n",
       "      <td>4238.000</td>\n",
       "      <td>4209.000</td>\n",
       "      <td>4185.00</td>\n",
       "      <td>4238.000</td>\n",
       "      <td>4238.000</td>\n",
       "      <td>4238.000</td>\n",
       "      <td>4188.000</td>\n",
       "      <td>4238.000</td>\n",
       "      <td>4238.000</td>\n",
       "      <td>4219.000</td>\n",
       "      <td>4237.000</td>\n",
       "      <td>3850.000</td>\n",
       "      <td>4238.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.429</td>\n",
       "      <td>49.585</td>\n",
       "      <td>1.979</td>\n",
       "      <td>0.494</td>\n",
       "      <td>9.003</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.311</td>\n",
       "      <td>0.026</td>\n",
       "      <td>236.722</td>\n",
       "      <td>132.352</td>\n",
       "      <td>82.893</td>\n",
       "      <td>25.802</td>\n",
       "      <td>75.879</td>\n",
       "      <td>81.967</td>\n",
       "      <td>0.152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.495</td>\n",
       "      <td>8.572</td>\n",
       "      <td>1.020</td>\n",
       "      <td>0.500</td>\n",
       "      <td>11.920</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.463</td>\n",
       "      <td>0.158</td>\n",
       "      <td>44.590</td>\n",
       "      <td>22.038</td>\n",
       "      <td>11.911</td>\n",
       "      <td>4.080</td>\n",
       "      <td>12.027</td>\n",
       "      <td>23.960</td>\n",
       "      <td>0.359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000</td>\n",
       "      <td>32.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>107.000</td>\n",
       "      <td>83.500</td>\n",
       "      <td>48.000</td>\n",
       "      <td>15.540</td>\n",
       "      <td>44.000</td>\n",
       "      <td>40.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000</td>\n",
       "      <td>42.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>206.000</td>\n",
       "      <td>117.000</td>\n",
       "      <td>75.000</td>\n",
       "      <td>23.070</td>\n",
       "      <td>68.000</td>\n",
       "      <td>71.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000</td>\n",
       "      <td>49.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>234.000</td>\n",
       "      <td>128.000</td>\n",
       "      <td>82.000</td>\n",
       "      <td>25.400</td>\n",
       "      <td>75.000</td>\n",
       "      <td>78.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000</td>\n",
       "      <td>56.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>263.000</td>\n",
       "      <td>144.000</td>\n",
       "      <td>89.875</td>\n",
       "      <td>28.040</td>\n",
       "      <td>83.000</td>\n",
       "      <td>87.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000</td>\n",
       "      <td>70.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>70.000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>696.000</td>\n",
       "      <td>295.000</td>\n",
       "      <td>142.500</td>\n",
       "      <td>56.800</td>\n",
       "      <td>143.000</td>\n",
       "      <td>394.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           male       age  education  ...  heartRate   glucose  TenYearCHD\n",
       "count  4238.000  4238.000   4133.000  ...   4237.000  3850.000    4238.000\n",
       "mean      0.429    49.585      1.979  ...     75.879    81.967       0.152\n",
       "std       0.495     8.572      1.020  ...     12.027    23.960       0.359\n",
       "min       0.000    32.000      1.000  ...     44.000    40.000       0.000\n",
       "25%       0.000    42.000      1.000  ...     68.000    71.000       0.000\n",
       "50%       0.000    49.000      2.000  ...     75.000    78.000       0.000\n",
       "75%       1.000    56.000      3.000  ...     83.000    87.000       0.000\n",
       "max       1.000    70.000      4.000  ...    143.000   394.000       1.000\n",
       "\n",
       "[8 rows x 16 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Description of data\n",
    "dfo.describe().round(decimals = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 546
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 858,
     "status": "ok",
     "timestamp": 1589722750948,
     "user": {
      "displayName": "Hoshi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgvJ9tk-7YVwMuT4roRhSvIVbF7D-gcIePVxYIukw=s64",
      "userId": "16228246563220513239"
     },
     "user_tz": -480
    },
    "id": "PClNwHQjdoAB",
    "outputId": "a3db700b-589a-4e1a-f99d-5fe0285137d0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>male</th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>currentSmoker</th>\n",
       "      <th>cigsPerDay</th>\n",
       "      <th>BPMeds</th>\n",
       "      <th>prevalentStroke</th>\n",
       "      <th>prevalentHyp</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>totChol</th>\n",
       "      <th>sysBP</th>\n",
       "      <th>diaBP</th>\n",
       "      <th>BMI</th>\n",
       "      <th>heartRate</th>\n",
       "      <th>glucose</th>\n",
       "      <th>TenYearCHD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>male</th>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.029</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.198</td>\n",
       "      <td>0.318</td>\n",
       "      <td>-0.053</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.016</td>\n",
       "      <td>-0.070</td>\n",
       "      <td>-0.036</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.082</td>\n",
       "      <td>-0.117</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>-0.029</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.166</td>\n",
       "      <td>-0.214</td>\n",
       "      <td>-0.193</td>\n",
       "      <td>0.123</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.307</td>\n",
       "      <td>0.101</td>\n",
       "      <td>0.262</td>\n",
       "      <td>0.394</td>\n",
       "      <td>0.206</td>\n",
       "      <td>0.136</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>0.122</td>\n",
       "      <td>0.225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>education</th>\n",
       "      <td>0.017</td>\n",
       "      <td>-0.166</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.008</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>-0.035</td>\n",
       "      <td>-0.082</td>\n",
       "      <td>-0.039</td>\n",
       "      <td>-0.023</td>\n",
       "      <td>-0.130</td>\n",
       "      <td>-0.062</td>\n",
       "      <td>-0.138</td>\n",
       "      <td>-0.054</td>\n",
       "      <td>-0.036</td>\n",
       "      <td>-0.054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>currentSmoker</th>\n",
       "      <td>0.198</td>\n",
       "      <td>-0.214</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.770</td>\n",
       "      <td>-0.049</td>\n",
       "      <td>-0.033</td>\n",
       "      <td>-0.103</td>\n",
       "      <td>-0.044</td>\n",
       "      <td>-0.047</td>\n",
       "      <td>-0.130</td>\n",
       "      <td>-0.108</td>\n",
       "      <td>-0.168</td>\n",
       "      <td>0.062</td>\n",
       "      <td>-0.057</td>\n",
       "      <td>0.019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cigsPerDay</th>\n",
       "      <td>0.318</td>\n",
       "      <td>-0.193</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.770</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>-0.033</td>\n",
       "      <td>-0.066</td>\n",
       "      <td>-0.037</td>\n",
       "      <td>-0.026</td>\n",
       "      <td>-0.089</td>\n",
       "      <td>-0.057</td>\n",
       "      <td>-0.093</td>\n",
       "      <td>0.075</td>\n",
       "      <td>-0.059</td>\n",
       "      <td>0.058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BPMeds</th>\n",
       "      <td>-0.053</td>\n",
       "      <td>0.123</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>-0.049</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.117</td>\n",
       "      <td>0.261</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.254</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0.101</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prevalentStroke</th>\n",
       "      <td>-0.005</td>\n",
       "      <td>0.058</td>\n",
       "      <td>-0.035</td>\n",
       "      <td>-0.033</td>\n",
       "      <td>-0.033</td>\n",
       "      <td>0.117</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.026</td>\n",
       "      <td>-0.018</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prevalentHyp</th>\n",
       "      <td>0.005</td>\n",
       "      <td>0.307</td>\n",
       "      <td>-0.082</td>\n",
       "      <td>-0.103</td>\n",
       "      <td>-0.066</td>\n",
       "      <td>0.261</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.697</td>\n",
       "      <td>0.616</td>\n",
       "      <td>0.301</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diabetes</th>\n",
       "      <td>0.016</td>\n",
       "      <td>0.101</td>\n",
       "      <td>-0.039</td>\n",
       "      <td>-0.044</td>\n",
       "      <td>-0.037</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.618</td>\n",
       "      <td>0.097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>totChol</th>\n",
       "      <td>-0.070</td>\n",
       "      <td>0.262</td>\n",
       "      <td>-0.023</td>\n",
       "      <td>-0.047</td>\n",
       "      <td>-0.026</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.209</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.116</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sysBP</th>\n",
       "      <td>-0.036</td>\n",
       "      <td>0.394</td>\n",
       "      <td>-0.130</td>\n",
       "      <td>-0.130</td>\n",
       "      <td>-0.089</td>\n",
       "      <td>0.254</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.697</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.209</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.784</td>\n",
       "      <td>0.327</td>\n",
       "      <td>0.182</td>\n",
       "      <td>0.141</td>\n",
       "      <td>0.216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diaBP</th>\n",
       "      <td>0.058</td>\n",
       "      <td>0.206</td>\n",
       "      <td>-0.062</td>\n",
       "      <td>-0.108</td>\n",
       "      <td>-0.057</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.616</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.784</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.378</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BMI</th>\n",
       "      <td>0.082</td>\n",
       "      <td>0.136</td>\n",
       "      <td>-0.138</td>\n",
       "      <td>-0.168</td>\n",
       "      <td>-0.093</td>\n",
       "      <td>0.101</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.301</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.116</td>\n",
       "      <td>0.327</td>\n",
       "      <td>0.378</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>heartRate</th>\n",
       "      <td>-0.117</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>-0.054</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.015</td>\n",
       "      <td>-0.018</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.182</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>glucose</th>\n",
       "      <td>0.006</td>\n",
       "      <td>0.122</td>\n",
       "      <td>-0.036</td>\n",
       "      <td>-0.057</td>\n",
       "      <td>-0.059</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.618</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.141</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TenYearCHD</th>\n",
       "      <td>0.088</td>\n",
       "      <td>0.225</td>\n",
       "      <td>-0.054</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.178</td>\n",
       "      <td>0.097</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.216</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  male    age  education  ...  heartRate  glucose  TenYearCHD\n",
       "male             0.000 -0.029      0.017  ...     -0.117    0.006       0.088\n",
       "age             -0.029  0.000     -0.166  ...     -0.013    0.122       0.225\n",
       "education        0.017 -0.166      0.000  ...     -0.054   -0.036      -0.054\n",
       "currentSmoker    0.198 -0.214      0.019  ...      0.062   -0.057       0.019\n",
       "cigsPerDay       0.318 -0.193      0.008  ...      0.075   -0.059       0.058\n",
       "BPMeds          -0.053  0.123     -0.011  ...      0.015    0.051       0.087\n",
       "prevalentStroke -0.005  0.058     -0.035  ...     -0.018    0.018       0.062\n",
       "prevalentHyp     0.005  0.307     -0.082  ...      0.147    0.087       0.178\n",
       "diabetes         0.016  0.101     -0.039  ...      0.049    0.618       0.097\n",
       "totChol         -0.070  0.262     -0.023  ...      0.091    0.046       0.082\n",
       "sysBP           -0.036  0.394     -0.130  ...      0.182    0.141       0.216\n",
       "diaBP            0.058  0.206     -0.062  ...      0.181    0.061       0.145\n",
       "BMI              0.082  0.136     -0.138  ...      0.068    0.087       0.075\n",
       "heartRate       -0.117 -0.013     -0.054  ...      0.000    0.095       0.023\n",
       "glucose          0.006  0.122     -0.036  ...      0.095    0.000       0.126\n",
       "TenYearCHD       0.088  0.225     -0.054  ...      0.023    0.126       0.000\n",
       "\n",
       "[16 rows x 16 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Correlation between features and labels\n",
    "cormat = dfo.corr()\n",
    "np.fill_diagonal(cormat.values, 0)\n",
    "cormat.round(decimals = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 633
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 952,
     "status": "ok",
     "timestamp": 1589722752902,
     "user": {
      "displayName": "Hoshi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgvJ9tk-7YVwMuT4roRhSvIVbF7D-gcIePVxYIukw=s64",
      "userId": "16228246563220513239"
     },
     "user_tz": -480
    },
    "id": "0RUl_3FnfJwv",
    "outputId": "42ee0af8-4186-44ba-c02e-22adfaeaae1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "male                  cigsPerDay\n",
      "age                        sysBP\n",
      "education          currentSmoker\n",
      "currentSmoker         cigsPerDay\n",
      "cigsPerDay         currentSmoker\n",
      "BPMeds              prevalentHyp\n",
      "prevalentStroke           BPMeds\n",
      "prevalentHyp               sysBP\n",
      "diabetes                 glucose\n",
      "totChol                      age\n",
      "sysBP                      diaBP\n",
      "diaBP                      sysBP\n",
      "BMI                        diaBP\n",
      "heartRate                  sysBP\n",
      "glucose                 diabetes\n",
      "TenYearCHD                   age\n",
      "dtype: object\n",
      "male               0.317930\n",
      "age                0.394302\n",
      "education          0.018532\n",
      "currentSmoker      0.769690\n",
      "cigsPerDay         0.769690\n",
      "BPMeds             0.261187\n",
      "prevalentStroke    0.117365\n",
      "prevalentHyp       0.696755\n",
      "diabetes           0.617627\n",
      "totChol            0.262131\n",
      "sysBP              0.784002\n",
      "diaBP              0.784002\n",
      "BMI                0.377588\n",
      "heartRate          0.182246\n",
      "glucose            0.617627\n",
      "TenYearCHD         0.225256\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Find the most correlated features\n",
    "print(cormat.idxmax())\n",
    "print(cormat.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 325
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 830,
     "status": "ok",
     "timestamp": 1589722754458,
     "user": {
      "displayName": "Hoshi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgvJ9tk-7YVwMuT4roRhSvIVbF7D-gcIePVxYIukw=s64",
      "userId": "16228246563220513239"
     },
     "user_tz": -480
    },
    "id": "OmQiK1PcXqKA",
    "outputId": "1a963309-a1ee-4c46-e910-b31d3bdfed91"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "male               False\n",
       "age                False\n",
       "education           True\n",
       "currentSmoker      False\n",
       "cigsPerDay          True\n",
       "BPMeds              True\n",
       "prevalentStroke    False\n",
       "prevalentHyp       False\n",
       "diabetes           False\n",
       "totChol             True\n",
       "sysBP              False\n",
       "diaBP              False\n",
       "BMI                 True\n",
       "heartRate           True\n",
       "glucose             True\n",
       "TenYearCHD         False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the column with NaN value(True indicate a column with missing value)\n",
    "# For later preprocessing on the missing data\n",
    "dfo.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 406
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1067,
     "status": "ok",
     "timestamp": 1589722756385,
     "user": {
      "displayName": "Hoshi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgvJ9tk-7YVwMuT4roRhSvIVbF7D-gcIePVxYIukw=s64",
      "userId": "16228246563220513239"
     },
     "user_tz": -480
    },
    "id": "yl6GRtHxGRXc",
    "outputId": "46c0a23e-1b59-49e8-c19c-8365ade7c333"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>male</th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>currentSmoker</th>\n",
       "      <th>cigsPerDay</th>\n",
       "      <th>BPMeds</th>\n",
       "      <th>prevalentStroke</th>\n",
       "      <th>prevalentHyp</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>totChol</th>\n",
       "      <th>sysBP</th>\n",
       "      <th>diaBP</th>\n",
       "      <th>BMI</th>\n",
       "      <th>heartRate</th>\n",
       "      <th>glucose</th>\n",
       "      <th>TenYearCHD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>26.97</td>\n",
       "      <td>80.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>28.73</td>\n",
       "      <td>95.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>127.5</td>\n",
       "      <td>80.0</td>\n",
       "      <td>25.34</td>\n",
       "      <td>75.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>28.58</td>\n",
       "      <td>65.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>23.10</td>\n",
       "      <td>85.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4233</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>313.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>25.97</td>\n",
       "      <td>66.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4234</th>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>207.0</td>\n",
       "      <td>126.5</td>\n",
       "      <td>80.0</td>\n",
       "      <td>19.71</td>\n",
       "      <td>65.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4235</th>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>248.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>22.00</td>\n",
       "      <td>84.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4236</th>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>126.5</td>\n",
       "      <td>87.0</td>\n",
       "      <td>19.16</td>\n",
       "      <td>86.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4237</th>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>269.0</td>\n",
       "      <td>133.5</td>\n",
       "      <td>83.0</td>\n",
       "      <td>21.47</td>\n",
       "      <td>80.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4238 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      male  age  education  ...  heartRate  glucose  TenYearCHD\n",
       "0        1   39        4.0  ...       80.0     77.0           0\n",
       "1        0   46        2.0  ...       95.0     76.0           0\n",
       "2        1   48        1.0  ...       75.0     70.0           0\n",
       "3        0   61        3.0  ...       65.0    103.0           1\n",
       "4        0   46        3.0  ...       85.0     85.0           0\n",
       "...    ...  ...        ...  ...        ...      ...         ...\n",
       "4233     1   50        1.0  ...       66.0     86.0           1\n",
       "4234     1   51        3.0  ...       65.0     68.0           0\n",
       "4235     0   48        2.0  ...       84.0     86.0           0\n",
       "4236     0   44        1.0  ...       86.0     82.0           0\n",
       "4237     0   52        2.0  ...       80.0    107.0           0\n",
       "\n",
       "[4238 rows x 16 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fill in the missing value with the mean\n",
    "df = dfo\n",
    "for i in range(0, len(df.columns) - 1):\n",
    "  if df.iloc[:, i].isna().any():\n",
    "    mean = round(df.iloc[:, i].mean())\n",
    "    df.iloc[:, i] = df.iloc[:, i].fillna(mean)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 325
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1116,
     "status": "ok",
     "timestamp": 1589722758090,
     "user": {
      "displayName": "Hoshi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgvJ9tk-7YVwMuT4roRhSvIVbF7D-gcIePVxYIukw=s64",
      "userId": "16228246563220513239"
     },
     "user_tz": -480
    },
    "id": "q2zvrDS_GPui",
    "outputId": "b42a8872-27ce-4dbc-9a8f-cc300d7f96d2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "male               False\n",
       "age                False\n",
       "education          False\n",
       "currentSmoker      False\n",
       "cigsPerDay         False\n",
       "BPMeds             False\n",
       "prevalentStroke    False\n",
       "prevalentHyp       False\n",
       "diabetes           False\n",
       "totChol            False\n",
       "sysBP              False\n",
       "diaBP              False\n",
       "BMI                False\n",
       "heartRate          False\n",
       "glucose            False\n",
       "TenYearCHD         False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make sure all columns have no NaN value \n",
    "df.isna().any() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 426
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1121,
     "status": "ok",
     "timestamp": 1589722760870,
     "user": {
      "displayName": "Hoshi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgvJ9tk-7YVwMuT4roRhSvIVbF7D-gcIePVxYIukw=s64",
      "userId": "16228246563220513239"
     },
     "user_tz": -480
    },
    "id": "GfgrdaaLfZG0",
    "outputId": "073557ad-ad02-4cef-9ff8-4c502ad0d5d5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>male</th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>currentSmoker</th>\n",
       "      <th>cigsPerDay</th>\n",
       "      <th>BPMeds</th>\n",
       "      <th>prevalentStroke</th>\n",
       "      <th>prevalentHyp</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>totChol</th>\n",
       "      <th>sysBP</th>\n",
       "      <th>diaBP</th>\n",
       "      <th>BMI</th>\n",
       "      <th>heartRate</th>\n",
       "      <th>glucose</th>\n",
       "      <th>TenYearCHD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.184</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.149</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.233</td>\n",
       "      <td>0.277</td>\n",
       "      <td>0.364</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.368</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.243</td>\n",
       "      <td>0.177</td>\n",
       "      <td>0.349</td>\n",
       "      <td>0.320</td>\n",
       "      <td>0.515</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.421</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.234</td>\n",
       "      <td>0.208</td>\n",
       "      <td>0.339</td>\n",
       "      <td>0.238</td>\n",
       "      <td>0.313</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.763</td>\n",
       "      <td>0.667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.314</td>\n",
       "      <td>0.497</td>\n",
       "      <td>0.316</td>\n",
       "      <td>0.212</td>\n",
       "      <td>0.178</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.368</td>\n",
       "      <td>0.667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.329</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.302</td>\n",
       "      <td>0.220</td>\n",
       "      <td>0.381</td>\n",
       "      <td>0.183</td>\n",
       "      <td>0.414</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4233</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.474</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.452</td>\n",
       "      <td>0.466</td>\n",
       "      <td>0.253</td>\n",
       "      <td>0.222</td>\n",
       "      <td>0.130</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4234</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.614</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.203</td>\n",
       "      <td>0.339</td>\n",
       "      <td>0.101</td>\n",
       "      <td>0.212</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4235</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.421</td>\n",
       "      <td>0.333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.239</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.254</td>\n",
       "      <td>0.157</td>\n",
       "      <td>0.404</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4236</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.316</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.214</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.203</td>\n",
       "      <td>0.413</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.424</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4237</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.526</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.275</td>\n",
       "      <td>0.236</td>\n",
       "      <td>0.370</td>\n",
       "      <td>0.144</td>\n",
       "      <td>0.364</td>\n",
       "      <td>0.189</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4238 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      male    age  education  ...  heartRate  glucose  TenYearCHD\n",
       "0      1.0  0.184      1.000  ...      0.364    0.105         0.0\n",
       "1      0.0  0.368      0.333  ...      0.515    0.102         0.0\n",
       "2      1.0  0.421      0.000  ...      0.313    0.085         0.0\n",
       "3      0.0  0.763      0.667  ...      0.212    0.178         1.0\n",
       "4      0.0  0.368      0.667  ...      0.414    0.127         0.0\n",
       "...    ...    ...        ...  ...        ...      ...         ...\n",
       "4233   1.0  0.474      0.000  ...      0.222    0.130         1.0\n",
       "4234   1.0  0.500      0.667  ...      0.212    0.079         0.0\n",
       "4235   0.0  0.421      0.333  ...      0.404    0.130         0.0\n",
       "4236   0.0  0.316      0.000  ...      0.424    0.119         0.0\n",
       "4237   0.0  0.526      0.333  ...      0.364    0.189         0.0\n",
       "\n",
       "[4238 rows x 16 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalization\n",
    "df.iloc[:, :] = MinMaxScaler().fit_transform(df)\n",
    "df.round(decimals = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tSEJshj7gCK1"
   },
   "outputs": [],
   "source": [
    "# Split the train&valid set and test set\n",
    "train_valid, test = train_test_split(df, test_size=0.2, random_state = 4211)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Csjg2M1hgE6Z"
   },
   "outputs": [],
   "source": [
    "# Split the train$valid set to train, valid\n",
    "train, valid = train_test_split(train_valid, test_size=0.2, random_state = 4211)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 998,
     "status": "ok",
     "timestamp": 1589722764832,
     "user": {
      "displayName": "Hoshi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgvJ9tk-7YVwMuT4roRhSvIVbF7D-gcIePVxYIukw=s64",
      "userId": "16228246563220513239"
     },
     "user_tz": -480
    },
    "id": "Ig0pIAqogJ9D",
    "outputId": "3ff2e902-5e1c-418d-f2c3-378dab03aef7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2712\n",
      "678\n",
      "848\n"
     ]
    }
   ],
   "source": [
    "# Size of the train valid and test dataframe\n",
    "print(len(train))\n",
    "print(len(valid))\n",
    "print(len(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7kjelSqVds8K"
   },
   "source": [
    "## **Sklearn Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Aue04l85Sg9k"
   },
   "source": [
    "### **Data Split and Cross-Validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wZZ7xRF0dv8T"
   },
   "outputs": [],
   "source": [
    "# Input Label Splitting\n",
    "train_valid_x = train_valid.iloc[:, 0:len(train.columns)-1]\n",
    "train_valid_y = train_valid.iloc[:, -1]\n",
    "train_x = train.iloc[:, 0:len(train.columns)-1]\n",
    "train_y = train.iloc[:, -1]\n",
    "valid_x = valid.iloc[:, 0:len(valid.columns)-1]\n",
    "valid_y = valid.iloc[:, -1]\n",
    "test_x = test.iloc[:, 0:len(test.columns)-1]\n",
    "test_y = test.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WMpFtLS6j8nr"
   },
   "outputs": [],
   "source": [
    "# Utility function to report best scores\n",
    "def report(results, n_top=100):\n",
    "    minsd = 999999\n",
    "    best = 0\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            if (results['std_test_score'][candidate] < minsd and i == 1):\n",
    "              minsd = results['std_test_score'][candidate]\n",
    "              best = candidate\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.6f} (std: {1:.6f})\"\n",
    "                  .format(results['mean_test_score'][candidate],\n",
    "                          results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")\n",
    "    return results['params'][best]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jNRufvg7jh5y"
   },
   "outputs": [],
   "source": [
    "# Hyperparameter Settings\n",
    "grid_params = {'hidden_layer_sizes': [(1, )],\n",
    "               'batch_size': [4, 32, 200],\n",
    "               'solver': ['sgd', 'adam'],\n",
    "               'learning_rate': ['constant', 'invscaling', 'adaptive'],\n",
    "               'learning_rate_init': [0.1, 0.001],\n",
    "               'activation': ['logistic'],\n",
    "               'max_iter': [1000],\n",
    "               'random_state': [4211]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rFWg7VlDLWaZ"
   },
   "outputs": [],
   "source": [
    "# Other parameters\n",
    "device = 'cuda'\n",
    "save_output = './Output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 642623,
     "status": "ok",
     "timestamp": 1589610327039,
     "user": {
      "displayName": "onion bob",
      "photoUrl": "",
      "userId": "16615051757072184496"
     },
     "user_tz": -480
    },
    "id": "hDzjUQM5kTOp",
    "outputId": "2567e80d-56c4-4929-aa65-cdfafffeae7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "[CV] activation=logistic, batch_size=4, hidden_layer_sizes=(1,), learning_rate=constant, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=sgd \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation=logistic, batch_size=4, hidden_layer_sizes=(1,), learning_rate=constant, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=sgd, score=0.847, total=   2.8s\n",
      "[CV] activation=logistic, batch_size=4, hidden_layer_sizes=(1,), learning_rate=constant, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=sgd \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation=logistic, batch_size=4, hidden_layer_sizes=(1,), learning_rate=constant, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=sgd, score=0.848, total=   2.0s\n",
      "[CV] activation=logistic, batch_size=4, hidden_layer_sizes=(1,), learning_rate=constant, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=sgd \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation=logistic, batch_size=4, hidden_layer_sizes=(1,), learning_rate=constant, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=sgd, score=0.848, total=   2.0s\n",
      "[CV] activation=logistic, batch_size=4, hidden_layer_sizes=(1,), learning_rate=constant, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=sgd \n",
      "[CV]  activation=logistic, batch_size=4, hidden_layer_sizes=(1,), learning_rate=constant, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=sgd, score=0.848, total=   2.3s\n",
      "[CV] activation=logistic, batch_size=4, hidden_layer_sizes=(1,), learning_rate=constant, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=sgd \n",
      "[CV]  activation=logistic, batch_size=4, hidden_layer_sizes=(1,), learning_rate=constant, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=sgd, score=0.848, total=   1.8s\n",
      "[CV] activation=logistic, batch_size=4, hidden_layer_sizes=(1,), learning_rate=constant, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=adam \n",
      "[CV]  activation=logistic, batch_size=4, hidden_layer_sizes=(1,), learning_rate=constant, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=adam, score=0.847, total=   2.9s\n",
      "[CV] activation=logistic, batch_size=4, hidden_layer_sizes=(1,), learning_rate=constant, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=adam \n",
      "[CV]  activation=logistic, batch_size=4, hidden_layer_sizes=(1,), learning_rate=constant, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=adam, score=0.848, total=   2.3s\n",
      "[CV] activation=logistic, batch_size=4, hidden_layer_sizes=(1,), learning_rate=constant, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=adam \n",
      "[CV]  activation=logistic, batch_size=4, hidden_layer_sizes=(1,), learning_rate=constant, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=adam, score=0.848, total=   2.6s\n",
      "[CV] activation=logistic, batch_size=4, hidden_layer_sizes=(1,), learning_rate=constant, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=adam \n",
      "[CV]  activation=logistic, batch_size=4, hidden_layer_sizes=(1,), learning_rate=constant, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=adam, score=0.848, total=   2.7s\n",
      "[CV] activation=logistic, batch_size=4, hidden_layer_sizes=(1,), learning_rate=constant, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=adam \n",
      "[CV]  activation=logistic, batch_size=4, hidden_layer_sizes=(1,), learning_rate=constant, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=adam, score=0.848, total=   4.3s\n",
      "[CV] activation=logistic, batch_size=4, hidden_layer_sizes=(1,), learning_rate=constant, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=sgd \n",
      "[CV]  activation=logistic, batch_size=4, hidden_layer_sizes=(1,), learning_rate=constant, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=sgd, score=0.847, total=  15.5s\n",
      "[CV] activation=logistic, batch_size=4, hidden_layer_sizes=(1,), learning_rate=constant, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=sgd \n",
      "[CV]  activation=logistic, batch_size=4, hidden_layer_sizes=(1,), learning_rate=constant, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=sgd, score=0.848, total=  14.0s\n",
      "[CV] activation=logistic, batch_size=4, hidden_layer_sizes=(1,), learning_rate=constant, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=sgd \n",
      "[CV]  activation=logistic, batch_size=4, hidden_layer_sizes=(1,), learning_rate=constant, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=sgd, score=0.848, total=  13.7s\n",
      "[CV] activation=logistic, batch_size=4, hidden_layer_sizes=(1,), learning_rate=constant, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=sgd \n",
      "[CV]  activation=logistic, batch_size=4, hidden_layer_sizes=(1,), learning_rate=constant, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=sgd, score=0.848, total=  12.0s\n",
      "[CV] activation=logistic, batch_size=4, hidden_layer_sizes=(1,), learning_rate=constant, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=sgd \n",
      "[CV]  activation=logistic, batch_size=4, hidden_layer_sizes=(1,), learning_rate=constant, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=sgd, score=0.848, total=  16.0s\n",
      "[CV] activation=logistic, batch_size=4, hidden_layer_sizes=(1,), learning_rate=constant, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=adam \n",
      "[CV]  activation=logistic, batch_size=4, hidden_layer_sizes=(1,), learning_rate=constant, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=adam, score=0.847, total=  14.2s\n",
      "[CV] activation=logistic, batch_size=4, hidden_layer_sizes=(1,), learning_rate=constant, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=adam \n",
      "[CV]  activation=logistic, batch_size=4, hidden_layer_sizes=(1,), learning_rate=constant, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=adam, score=0.848, total=  17.8s\n",
      "[CV] activation=logistic, batch_size=4, hidden_layer_sizes=(1,), learning_rate=constant, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=adam \n",
      "[CV]  activation=logistic, batch_size=4, hidden_layer_sizes=(1,), learning_rate=constant, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=adam, score=0.848, total=  12.5s\n",
      "[CV] activation=logistic, batch_size=4, hidden_layer_sizes=(1,), learning_rate=constant, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=adam \n",
      "[CV]  activation=logistic, batch_size=4, hidden_layer_sizes=(1,), learning_rate=constant, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=adam, score=0.848, total=  13.7s\n",
      "[CV] activation=logistic, batch_size=4, hidden_layer_sizes=(1,), learning_rate=constant, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=adam \n",
      "[CV]  activation=logistic, batch_size=4, hidden_layer_sizes=(1,), learning_rate=constant, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=adam, score=0.848, total=  14.6s\n",
      "[CV] activation=logistic, batch_size=4, hidden_layer_sizes=(1,), learning_rate=invscaling, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=sgd \n",
      "[CV]  activation=logistic, batch_size=4, hidden_layer_sizes=(1,), learning_rate=invscaling, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=sgd, score=0.847, total=   4.1s\n",
      "[CV] activation=logistic, batch_size=4, hidden_layer_sizes=(1,), learning_rate=invscaling, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=sgd \n",
      "[CV]  activation=logistic, batch_size=4, hidden_layer_sizes=(1,), learning_rate=invscaling, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=sgd, score=0.848, total=   3.3s\n",
      "[CV] activation=logistic, batch_size=4, hidden_layer_sizes=(1,), learning_rate=invscaling, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=sgd \n",
      "[CV]  activation=logistic, batch_size=4, hidden_layer_sizes=(1,), learning_rate=invscaling, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=sgd, score=0.848, total=   3.2s\n",
      "[CV] activation=logistic, batch_size=4, hidden_layer_sizes=(1,), learning_rate=invscaling, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=sgd \n",
      "[CV]  activation=logistic, batch_size=4, hidden_layer_sizes=(1,), learning_rate=invscaling, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=sgd, score=0.848, total=   3.8s\n",
      "[CV] activation=logistic, batch_size=4, hidden_layer_sizes=(1,), learning_rate=invscaling, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=sgd \n",
      "[CV]  activation=logistic, batch_size=4, hidden_layer_sizes=(1,), learning_rate=invscaling, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=sgd, score=0.848, total=   3.4s\n",
      "[CV] activation=logistic, batch_size=4, hidden_layer_sizes=(1,), learning_rate=invscaling, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=adam \n",
      "[CV]  activation=logistic, batch_size=4, hidden_layer_sizes=(1,), learning_rate=invscaling, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=adam, score=0.847, total=   3.0s\n",
      "[CV] activation=logistic, batch_size=4, hidden_layer_sizes=(1,), learning_rate=invscaling, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=adam \n",
      "[CV]  activation=logistic, batch_size=4, hidden_layer_sizes=(1,), learning_rate=invscaling, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=adam, score=0.848, total=   2.4s\n",
      "[CV] activation=logistic, batch_size=4, hidden_layer_sizes=(1,), learning_rate=invscaling, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=adam \n",
      "[CV]  activation=logistic, batch_size=4, hidden_layer_sizes=(1,), learning_rate=invscaling, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=adam, score=0.848, total=   2.6s\n",
      "[CV] activation=logistic, batch_size=4, hidden_layer_sizes=(1,), learning_rate=invscaling, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=adam \n",
      "[CV]  activation=logistic, batch_size=4, hidden_layer_sizes=(1,), learning_rate=invscaling, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=adam, score=0.848, total=   2.9s\n",
      "[CV] activation=logistic, batch_size=4, hidden_layer_sizes=(1,), learning_rate=invscaling, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=adam \n",
      "[CV]  activation=logistic, batch_size=4, hidden_layer_sizes=(1,), learning_rate=invscaling, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=adam, score=0.848, total=   4.3s\n",
      "[CV] activation=logistic, batch_size=4, hidden_layer_sizes=(1,), learning_rate=invscaling, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=sgd \n",
      "[CV]  activation=logistic, batch_size=4, hidden_layer_sizes=(1,), learning_rate=invscaling, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=sgd, score=0.847, total=   3.9s\n",
      "[CV] activation=logistic, batch_size=4, hidden_layer_sizes=(1,), learning_rate=invscaling, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=sgd \n",
      "[CV]  activation=logistic, batch_size=4, hidden_layer_sizes=(1,), learning_rate=invscaling, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=sgd, score=0.848, total=   4.1s\n",
      "[CV] activation=logistic, batch_size=4, hidden_layer_sizes=(1,), learning_rate=invscaling, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=sgd \n",
      "[CV]  activation=logistic, batch_size=4, hidden_layer_sizes=(1,), learning_rate=invscaling, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=sgd, score=0.848, total=   4.0s\n",
      "[CV] activation=logistic, batch_size=4, hidden_layer_sizes=(1,), learning_rate=invscaling, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=sgd \n",
      "[CV]  activation=logistic, batch_size=4, hidden_layer_sizes=(1,), learning_rate=invscaling, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=sgd, score=0.848, total=   3.8s\n",
      "[CV] activation=logistic, batch_size=4, hidden_layer_sizes=(1,), learning_rate=invscaling, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=sgd \n",
      "[CV]  activation=logistic, batch_size=4, hidden_layer_sizes=(1,), learning_rate=invscaling, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=sgd, score=0.848, total=   3.9s\n",
      "[CV] activation=logistic, batch_size=4, hidden_layer_sizes=(1,), learning_rate=invscaling, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=adam \n",
      "[CV]  activation=logistic, batch_size=4, hidden_layer_sizes=(1,), learning_rate=invscaling, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=adam, score=0.847, total=  14.3s\n",
      "[CV] activation=logistic, batch_size=4, hidden_layer_sizes=(1,), learning_rate=invscaling, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=adam \n",
      "[CV]  activation=logistic, batch_size=4, hidden_layer_sizes=(1,), learning_rate=invscaling, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=adam, score=0.848, total=  17.8s\n",
      "[CV] activation=logistic, batch_size=4, hidden_layer_sizes=(1,), learning_rate=invscaling, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=adam \n",
      "[CV]  activation=logistic, batch_size=4, hidden_layer_sizes=(1,), learning_rate=invscaling, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=adam, score=0.848, total=  12.7s\n",
      "[CV] activation=logistic, batch_size=4, hidden_layer_sizes=(1,), learning_rate=invscaling, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=adam \n",
      "[CV]  activation=logistic, batch_size=4, hidden_layer_sizes=(1,), learning_rate=invscaling, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=adam, score=0.848, total=  13.6s\n",
      "[CV] activation=logistic, batch_size=4, hidden_layer_sizes=(1,), learning_rate=invscaling, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=adam \n",
      "[CV]  activation=logistic, batch_size=4, hidden_layer_sizes=(1,), learning_rate=invscaling, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=adam, score=0.848, total=  14.5s\n",
      "[CV] activation=logistic, batch_size=4, hidden_layer_sizes=(1,), learning_rate=adaptive, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=sgd \n",
      "[CV]  activation=logistic, batch_size=4, hidden_layer_sizes=(1,), learning_rate=adaptive, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=sgd, score=0.847, total=  11.0s\n",
      "[CV] activation=logistic, batch_size=4, hidden_layer_sizes=(1,), learning_rate=adaptive, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=sgd \n",
      "[CV]  activation=logistic, batch_size=4, hidden_layer_sizes=(1,), learning_rate=adaptive, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=sgd, score=0.848, total=  10.8s\n",
      "[CV] activation=logistic, batch_size=4, hidden_layer_sizes=(1,), learning_rate=adaptive, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=sgd \n",
      "[CV]  activation=logistic, batch_size=4, hidden_layer_sizes=(1,), learning_rate=adaptive, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=sgd, score=0.848, total=  11.1s\n",
      "[CV] activation=logistic, batch_size=4, hidden_layer_sizes=(1,), learning_rate=adaptive, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=sgd \n",
      "[CV]  activation=logistic, batch_size=4, hidden_layer_sizes=(1,), learning_rate=adaptive, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=sgd, score=0.848, total=  11.8s\n",
      "[CV] activation=logistic, batch_size=4, hidden_layer_sizes=(1,), learning_rate=adaptive, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=sgd \n",
      "[CV]  activation=logistic, batch_size=4, hidden_layer_sizes=(1,), learning_rate=adaptive, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=sgd, score=0.848, total=  10.6s\n",
      "[CV] activation=logistic, batch_size=4, hidden_layer_sizes=(1,), learning_rate=adaptive, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=adam \n",
      "[CV]  activation=logistic, batch_size=4, hidden_layer_sizes=(1,), learning_rate=adaptive, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=adam, score=0.847, total=   2.9s\n",
      "[CV] activation=logistic, batch_size=4, hidden_layer_sizes=(1,), learning_rate=adaptive, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=adam \n",
      "[CV]  activation=logistic, batch_size=4, hidden_layer_sizes=(1,), learning_rate=adaptive, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=adam, score=0.848, total=   2.3s\n",
      "[CV] activation=logistic, batch_size=4, hidden_layer_sizes=(1,), learning_rate=adaptive, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=adam \n",
      "[CV]  activation=logistic, batch_size=4, hidden_layer_sizes=(1,), learning_rate=adaptive, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=adam, score=0.848, total=   2.6s\n",
      "[CV] activation=logistic, batch_size=4, hidden_layer_sizes=(1,), learning_rate=adaptive, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=adam \n",
      "[CV]  activation=logistic, batch_size=4, hidden_layer_sizes=(1,), learning_rate=adaptive, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=adam, score=0.848, total=   2.8s\n",
      "[CV] activation=logistic, batch_size=4, hidden_layer_sizes=(1,), learning_rate=adaptive, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=adam \n",
      "[CV]  activation=logistic, batch_size=4, hidden_layer_sizes=(1,), learning_rate=adaptive, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=adam, score=0.848, total=   4.3s\n",
      "[CV] activation=logistic, batch_size=4, hidden_layer_sizes=(1,), learning_rate=adaptive, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=sgd \n",
      "[CV]  activation=logistic, batch_size=4, hidden_layer_sizes=(1,), learning_rate=adaptive, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=sgd, score=0.847, total=  20.0s\n",
      "[CV] activation=logistic, batch_size=4, hidden_layer_sizes=(1,), learning_rate=adaptive, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=sgd \n",
      "[CV]  activation=logistic, batch_size=4, hidden_layer_sizes=(1,), learning_rate=adaptive, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=sgd, score=0.848, total=  18.7s\n",
      "[CV] activation=logistic, batch_size=4, hidden_layer_sizes=(1,), learning_rate=adaptive, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=sgd \n",
      "[CV]  activation=logistic, batch_size=4, hidden_layer_sizes=(1,), learning_rate=adaptive, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=sgd, score=0.848, total=  18.9s\n",
      "[CV] activation=logistic, batch_size=4, hidden_layer_sizes=(1,), learning_rate=adaptive, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=sgd \n",
      "[CV]  activation=logistic, batch_size=4, hidden_layer_sizes=(1,), learning_rate=adaptive, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=sgd, score=0.848, total=  16.8s\n",
      "[CV] activation=logistic, batch_size=4, hidden_layer_sizes=(1,), learning_rate=adaptive, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=sgd \n",
      "[CV]  activation=logistic, batch_size=4, hidden_layer_sizes=(1,), learning_rate=adaptive, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=sgd, score=0.848, total=  20.8s\n",
      "[CV] activation=logistic, batch_size=4, hidden_layer_sizes=(1,), learning_rate=adaptive, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=adam \n",
      "[CV]  activation=logistic, batch_size=4, hidden_layer_sizes=(1,), learning_rate=adaptive, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=adam, score=0.847, total=  14.2s\n",
      "[CV] activation=logistic, batch_size=4, hidden_layer_sizes=(1,), learning_rate=adaptive, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=adam \n",
      "[CV]  activation=logistic, batch_size=4, hidden_layer_sizes=(1,), learning_rate=adaptive, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=adam, score=0.848, total=  17.9s\n",
      "[CV] activation=logistic, batch_size=4, hidden_layer_sizes=(1,), learning_rate=adaptive, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=adam \n",
      "[CV]  activation=logistic, batch_size=4, hidden_layer_sizes=(1,), learning_rate=adaptive, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=adam, score=0.848, total=  12.6s\n",
      "[CV] activation=logistic, batch_size=4, hidden_layer_sizes=(1,), learning_rate=adaptive, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=adam \n",
      "[CV]  activation=logistic, batch_size=4, hidden_layer_sizes=(1,), learning_rate=adaptive, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=adam, score=0.848, total=  13.6s\n",
      "[CV] activation=logistic, batch_size=4, hidden_layer_sizes=(1,), learning_rate=adaptive, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=adam \n",
      "[CV]  activation=logistic, batch_size=4, hidden_layer_sizes=(1,), learning_rate=adaptive, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=adam, score=0.848, total=  14.6s\n",
      "[CV] activation=logistic, batch_size=32, hidden_layer_sizes=(1,), learning_rate=constant, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=sgd \n",
      "[CV]  activation=logistic, batch_size=32, hidden_layer_sizes=(1,), learning_rate=constant, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=sgd, score=0.847, total=   0.7s\n",
      "[CV] activation=logistic, batch_size=32, hidden_layer_sizes=(1,), learning_rate=constant, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=sgd \n",
      "[CV]  activation=logistic, batch_size=32, hidden_layer_sizes=(1,), learning_rate=constant, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=sgd, score=0.848, total=   0.5s\n",
      "[CV] activation=logistic, batch_size=32, hidden_layer_sizes=(1,), learning_rate=constant, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=sgd \n",
      "[CV]  activation=logistic, batch_size=32, hidden_layer_sizes=(1,), learning_rate=constant, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=sgd, score=0.848, total=   0.6s\n",
      "[CV] activation=logistic, batch_size=32, hidden_layer_sizes=(1,), learning_rate=constant, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=sgd \n",
      "[CV]  activation=logistic, batch_size=32, hidden_layer_sizes=(1,), learning_rate=constant, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=sgd, score=0.848, total=   0.5s\n",
      "[CV] activation=logistic, batch_size=32, hidden_layer_sizes=(1,), learning_rate=constant, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=sgd \n",
      "[CV]  activation=logistic, batch_size=32, hidden_layer_sizes=(1,), learning_rate=constant, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=sgd, score=0.848, total=   0.5s\n",
      "[CV] activation=logistic, batch_size=32, hidden_layer_sizes=(1,), learning_rate=constant, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=adam \n",
      "[CV]  activation=logistic, batch_size=32, hidden_layer_sizes=(1,), learning_rate=constant, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=adam, score=0.847, total=   0.5s\n",
      "[CV] activation=logistic, batch_size=32, hidden_layer_sizes=(1,), learning_rate=constant, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=adam \n",
      "[CV]  activation=logistic, batch_size=32, hidden_layer_sizes=(1,), learning_rate=constant, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=adam, score=0.848, total=   0.6s\n",
      "[CV] activation=logistic, batch_size=32, hidden_layer_sizes=(1,), learning_rate=constant, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=adam \n",
      "[CV]  activation=logistic, batch_size=32, hidden_layer_sizes=(1,), learning_rate=constant, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=adam, score=0.848, total=   0.5s\n",
      "[CV] activation=logistic, batch_size=32, hidden_layer_sizes=(1,), learning_rate=constant, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=adam \n",
      "[CV]  activation=logistic, batch_size=32, hidden_layer_sizes=(1,), learning_rate=constant, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=adam, score=0.848, total=   0.6s\n",
      "[CV] activation=logistic, batch_size=32, hidden_layer_sizes=(1,), learning_rate=constant, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=adam \n",
      "[CV]  activation=logistic, batch_size=32, hidden_layer_sizes=(1,), learning_rate=constant, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=adam, score=0.848, total=   0.6s\n",
      "[CV] activation=logistic, batch_size=32, hidden_layer_sizes=(1,), learning_rate=constant, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=sgd \n",
      "[CV]  activation=logistic, batch_size=32, hidden_layer_sizes=(1,), learning_rate=constant, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=sgd, score=0.847, total=   0.5s\n",
      "[CV] activation=logistic, batch_size=32, hidden_layer_sizes=(1,), learning_rate=constant, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=sgd \n",
      "[CV]  activation=logistic, batch_size=32, hidden_layer_sizes=(1,), learning_rate=constant, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=sgd, score=0.848, total=   0.5s\n",
      "[CV] activation=logistic, batch_size=32, hidden_layer_sizes=(1,), learning_rate=constant, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=sgd \n",
      "[CV]  activation=logistic, batch_size=32, hidden_layer_sizes=(1,), learning_rate=constant, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=sgd, score=0.848, total=   0.5s\n",
      "[CV] activation=logistic, batch_size=32, hidden_layer_sizes=(1,), learning_rate=constant, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=sgd \n",
      "[CV]  activation=logistic, batch_size=32, hidden_layer_sizes=(1,), learning_rate=constant, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=sgd, score=0.848, total=   0.5s\n",
      "[CV] activation=logistic, batch_size=32, hidden_layer_sizes=(1,), learning_rate=constant, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=sgd \n",
      "[CV]  activation=logistic, batch_size=32, hidden_layer_sizes=(1,), learning_rate=constant, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=sgd, score=0.848, total=   0.5s\n",
      "[CV] activation=logistic, batch_size=32, hidden_layer_sizes=(1,), learning_rate=constant, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=adam \n",
      "[CV]  activation=logistic, batch_size=32, hidden_layer_sizes=(1,), learning_rate=constant, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=adam, score=0.847, total=   0.8s\n",
      "[CV] activation=logistic, batch_size=32, hidden_layer_sizes=(1,), learning_rate=constant, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=adam \n",
      "[CV]  activation=logistic, batch_size=32, hidden_layer_sizes=(1,), learning_rate=constant, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=adam, score=0.848, total=   0.8s\n",
      "[CV] activation=logistic, batch_size=32, hidden_layer_sizes=(1,), learning_rate=constant, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=adam \n",
      "[CV]  activation=logistic, batch_size=32, hidden_layer_sizes=(1,), learning_rate=constant, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=adam, score=0.848, total=   0.8s\n",
      "[CV] activation=logistic, batch_size=32, hidden_layer_sizes=(1,), learning_rate=constant, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=adam \n",
      "[CV]  activation=logistic, batch_size=32, hidden_layer_sizes=(1,), learning_rate=constant, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=adam, score=0.848, total=   0.8s\n",
      "[CV] activation=logistic, batch_size=32, hidden_layer_sizes=(1,), learning_rate=constant, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=adam \n",
      "[CV]  activation=logistic, batch_size=32, hidden_layer_sizes=(1,), learning_rate=constant, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=adam, score=0.848, total=   0.8s\n",
      "[CV] activation=logistic, batch_size=32, hidden_layer_sizes=(1,), learning_rate=invscaling, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=sgd \n",
      "[CV]  activation=logistic, batch_size=32, hidden_layer_sizes=(1,), learning_rate=invscaling, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=sgd, score=0.847, total=   0.2s\n",
      "[CV] activation=logistic, batch_size=32, hidden_layer_sizes=(1,), learning_rate=invscaling, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=sgd \n",
      "[CV]  activation=logistic, batch_size=32, hidden_layer_sizes=(1,), learning_rate=invscaling, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=sgd, score=0.848, total=   0.3s\n",
      "[CV] activation=logistic, batch_size=32, hidden_layer_sizes=(1,), learning_rate=invscaling, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=sgd \n",
      "[CV]  activation=logistic, batch_size=32, hidden_layer_sizes=(1,), learning_rate=invscaling, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=sgd, score=0.848, total=   0.3s\n",
      "[CV] activation=logistic, batch_size=32, hidden_layer_sizes=(1,), learning_rate=invscaling, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=sgd \n",
      "[CV]  activation=logistic, batch_size=32, hidden_layer_sizes=(1,), learning_rate=invscaling, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=sgd, score=0.848, total=   0.2s\n",
      "[CV] activation=logistic, batch_size=32, hidden_layer_sizes=(1,), learning_rate=invscaling, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=sgd \n",
      "[CV]  activation=logistic, batch_size=32, hidden_layer_sizes=(1,), learning_rate=invscaling, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=sgd, score=0.848, total=   0.2s\n",
      "[CV] activation=logistic, batch_size=32, hidden_layer_sizes=(1,), learning_rate=invscaling, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=adam \n",
      "[CV]  activation=logistic, batch_size=32, hidden_layer_sizes=(1,), learning_rate=invscaling, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=adam, score=0.847, total=   0.5s\n",
      "[CV] activation=logistic, batch_size=32, hidden_layer_sizes=(1,), learning_rate=invscaling, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=adam \n",
      "[CV]  activation=logistic, batch_size=32, hidden_layer_sizes=(1,), learning_rate=invscaling, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=adam, score=0.848, total=   0.6s\n",
      "[CV] activation=logistic, batch_size=32, hidden_layer_sizes=(1,), learning_rate=invscaling, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=adam \n",
      "[CV]  activation=logistic, batch_size=32, hidden_layer_sizes=(1,), learning_rate=invscaling, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=adam, score=0.848, total=   0.5s\n",
      "[CV] activation=logistic, batch_size=32, hidden_layer_sizes=(1,), learning_rate=invscaling, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=adam \n",
      "[CV]  activation=logistic, batch_size=32, hidden_layer_sizes=(1,), learning_rate=invscaling, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=adam, score=0.848, total=   0.6s\n",
      "[CV] activation=logistic, batch_size=32, hidden_layer_sizes=(1,), learning_rate=invscaling, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=adam \n",
      "[CV]  activation=logistic, batch_size=32, hidden_layer_sizes=(1,), learning_rate=invscaling, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=adam, score=0.848, total=   0.6s\n",
      "[CV] activation=logistic, batch_size=32, hidden_layer_sizes=(1,), learning_rate=invscaling, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=sgd \n",
      "[CV]  activation=logistic, batch_size=32, hidden_layer_sizes=(1,), learning_rate=invscaling, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=sgd, score=0.829, total=   8.0s\n",
      "[CV] activation=logistic, batch_size=32, hidden_layer_sizes=(1,), learning_rate=invscaling, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=sgd \n",
      "[CV]  activation=logistic, batch_size=32, hidden_layer_sizes=(1,), learning_rate=invscaling, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=sgd, score=0.814, total=   8.0s\n",
      "[CV] activation=logistic, batch_size=32, hidden_layer_sizes=(1,), learning_rate=invscaling, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=sgd \n",
      "[CV]  activation=logistic, batch_size=32, hidden_layer_sizes=(1,), learning_rate=invscaling, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=sgd, score=0.813, total=   8.3s\n",
      "[CV] activation=logistic, batch_size=32, hidden_layer_sizes=(1,), learning_rate=invscaling, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=sgd \n",
      "[CV]  activation=logistic, batch_size=32, hidden_layer_sizes=(1,), learning_rate=invscaling, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=sgd, score=0.816, total=   8.2s\n",
      "[CV] activation=logistic, batch_size=32, hidden_layer_sizes=(1,), learning_rate=invscaling, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=sgd \n",
      "[CV]  activation=logistic, batch_size=32, hidden_layer_sizes=(1,), learning_rate=invscaling, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=sgd, score=0.817, total=   8.0s\n",
      "[CV] activation=logistic, batch_size=32, hidden_layer_sizes=(1,), learning_rate=invscaling, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=adam \n",
      "[CV]  activation=logistic, batch_size=32, hidden_layer_sizes=(1,), learning_rate=invscaling, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=adam, score=0.847, total=   0.8s\n",
      "[CV] activation=logistic, batch_size=32, hidden_layer_sizes=(1,), learning_rate=invscaling, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=adam \n",
      "[CV]  activation=logistic, batch_size=32, hidden_layer_sizes=(1,), learning_rate=invscaling, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=adam, score=0.848, total=   0.8s\n",
      "[CV] activation=logistic, batch_size=32, hidden_layer_sizes=(1,), learning_rate=invscaling, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=adam \n",
      "[CV]  activation=logistic, batch_size=32, hidden_layer_sizes=(1,), learning_rate=invscaling, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=adam, score=0.848, total=   0.8s\n",
      "[CV] activation=logistic, batch_size=32, hidden_layer_sizes=(1,), learning_rate=invscaling, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=adam \n",
      "[CV]  activation=logistic, batch_size=32, hidden_layer_sizes=(1,), learning_rate=invscaling, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=adam, score=0.848, total=   0.8s\n",
      "[CV] activation=logistic, batch_size=32, hidden_layer_sizes=(1,), learning_rate=invscaling, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=adam \n",
      "[CV]  activation=logistic, batch_size=32, hidden_layer_sizes=(1,), learning_rate=invscaling, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=adam, score=0.848, total=   0.8s\n",
      "[CV] activation=logistic, batch_size=32, hidden_layer_sizes=(1,), learning_rate=adaptive, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=sgd \n",
      "[CV]  activation=logistic, batch_size=32, hidden_layer_sizes=(1,), learning_rate=adaptive, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=sgd, score=0.847, total=   1.9s\n",
      "[CV] activation=logistic, batch_size=32, hidden_layer_sizes=(1,), learning_rate=adaptive, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=sgd \n",
      "[CV]  activation=logistic, batch_size=32, hidden_layer_sizes=(1,), learning_rate=adaptive, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=sgd, score=0.848, total=   1.7s\n",
      "[CV] activation=logistic, batch_size=32, hidden_layer_sizes=(1,), learning_rate=adaptive, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=sgd \n",
      "[CV]  activation=logistic, batch_size=32, hidden_layer_sizes=(1,), learning_rate=adaptive, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=sgd, score=0.850, total=   1.8s\n",
      "[CV] activation=logistic, batch_size=32, hidden_layer_sizes=(1,), learning_rate=adaptive, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=sgd \n",
      "[CV]  activation=logistic, batch_size=32, hidden_layer_sizes=(1,), learning_rate=adaptive, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=sgd, score=0.848, total=   1.7s\n",
      "[CV] activation=logistic, batch_size=32, hidden_layer_sizes=(1,), learning_rate=adaptive, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=sgd \n",
      "[CV]  activation=logistic, batch_size=32, hidden_layer_sizes=(1,), learning_rate=adaptive, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=sgd, score=0.848, total=   1.8s\n",
      "[CV] activation=logistic, batch_size=32, hidden_layer_sizes=(1,), learning_rate=adaptive, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=adam \n",
      "[CV]  activation=logistic, batch_size=32, hidden_layer_sizes=(1,), learning_rate=adaptive, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=adam, score=0.847, total=   0.5s\n",
      "[CV] activation=logistic, batch_size=32, hidden_layer_sizes=(1,), learning_rate=adaptive, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=adam \n",
      "[CV]  activation=logistic, batch_size=32, hidden_layer_sizes=(1,), learning_rate=adaptive, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=adam, score=0.848, total=   0.6s\n",
      "[CV] activation=logistic, batch_size=32, hidden_layer_sizes=(1,), learning_rate=adaptive, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=adam \n",
      "[CV]  activation=logistic, batch_size=32, hidden_layer_sizes=(1,), learning_rate=adaptive, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=adam, score=0.848, total=   0.5s\n",
      "[CV] activation=logistic, batch_size=32, hidden_layer_sizes=(1,), learning_rate=adaptive, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=adam \n",
      "[CV]  activation=logistic, batch_size=32, hidden_layer_sizes=(1,), learning_rate=adaptive, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=adam, score=0.848, total=   0.6s\n",
      "[CV] activation=logistic, batch_size=32, hidden_layer_sizes=(1,), learning_rate=adaptive, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=adam \n",
      "[CV]  activation=logistic, batch_size=32, hidden_layer_sizes=(1,), learning_rate=adaptive, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=adam, score=0.848, total=   0.6s\n",
      "[CV] activation=logistic, batch_size=32, hidden_layer_sizes=(1,), learning_rate=adaptive, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=sgd \n",
      "[CV]  activation=logistic, batch_size=32, hidden_layer_sizes=(1,), learning_rate=adaptive, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=sgd, score=0.847, total=   1.2s\n",
      "[CV] activation=logistic, batch_size=32, hidden_layer_sizes=(1,), learning_rate=adaptive, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=sgd \n",
      "[CV]  activation=logistic, batch_size=32, hidden_layer_sizes=(1,), learning_rate=adaptive, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=sgd, score=0.848, total=   1.2s\n",
      "[CV] activation=logistic, batch_size=32, hidden_layer_sizes=(1,), learning_rate=adaptive, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=sgd \n",
      "[CV]  activation=logistic, batch_size=32, hidden_layer_sizes=(1,), learning_rate=adaptive, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=sgd, score=0.848, total=   1.2s\n",
      "[CV] activation=logistic, batch_size=32, hidden_layer_sizes=(1,), learning_rate=adaptive, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=sgd \n",
      "[CV]  activation=logistic, batch_size=32, hidden_layer_sizes=(1,), learning_rate=adaptive, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=sgd, score=0.848, total=   1.2s\n",
      "[CV] activation=logistic, batch_size=32, hidden_layer_sizes=(1,), learning_rate=adaptive, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=sgd \n",
      "[CV]  activation=logistic, batch_size=32, hidden_layer_sizes=(1,), learning_rate=adaptive, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=sgd, score=0.848, total=   1.2s\n",
      "[CV] activation=logistic, batch_size=32, hidden_layer_sizes=(1,), learning_rate=adaptive, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=adam \n",
      "[CV]  activation=logistic, batch_size=32, hidden_layer_sizes=(1,), learning_rate=adaptive, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=adam, score=0.847, total=   0.8s\n",
      "[CV] activation=logistic, batch_size=32, hidden_layer_sizes=(1,), learning_rate=adaptive, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=adam \n",
      "[CV]  activation=logistic, batch_size=32, hidden_layer_sizes=(1,), learning_rate=adaptive, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=adam, score=0.848, total=   0.8s\n",
      "[CV] activation=logistic, batch_size=32, hidden_layer_sizes=(1,), learning_rate=adaptive, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=adam \n",
      "[CV]  activation=logistic, batch_size=32, hidden_layer_sizes=(1,), learning_rate=adaptive, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=adam, score=0.848, total=   0.8s\n",
      "[CV] activation=logistic, batch_size=32, hidden_layer_sizes=(1,), learning_rate=adaptive, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=adam \n",
      "[CV]  activation=logistic, batch_size=32, hidden_layer_sizes=(1,), learning_rate=adaptive, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=adam, score=0.848, total=   0.8s\n",
      "[CV] activation=logistic, batch_size=32, hidden_layer_sizes=(1,), learning_rate=adaptive, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=adam \n",
      "[CV]  activation=logistic, batch_size=32, hidden_layer_sizes=(1,), learning_rate=adaptive, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=adam, score=0.848, total=   0.8s\n",
      "[CV] activation=logistic, batch_size=200, hidden_layer_sizes=(1,), learning_rate=constant, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=sgd \n",
      "[CV]  activation=logistic, batch_size=200, hidden_layer_sizes=(1,), learning_rate=constant, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=sgd, score=0.847, total=   0.3s\n",
      "[CV] activation=logistic, batch_size=200, hidden_layer_sizes=(1,), learning_rate=constant, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=sgd \n",
      "[CV]  activation=logistic, batch_size=200, hidden_layer_sizes=(1,), learning_rate=constant, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=sgd, score=0.848, total=   0.3s\n",
      "[CV] activation=logistic, batch_size=200, hidden_layer_sizes=(1,), learning_rate=constant, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=sgd \n",
      "[CV]  activation=logistic, batch_size=200, hidden_layer_sizes=(1,), learning_rate=constant, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=sgd, score=0.850, total=   0.3s\n",
      "[CV] activation=logistic, batch_size=200, hidden_layer_sizes=(1,), learning_rate=constant, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=sgd \n",
      "[CV]  activation=logistic, batch_size=200, hidden_layer_sizes=(1,), learning_rate=constant, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=sgd, score=0.848, total=   0.3s\n",
      "[CV] activation=logistic, batch_size=200, hidden_layer_sizes=(1,), learning_rate=constant, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=sgd \n",
      "[CV]  activation=logistic, batch_size=200, hidden_layer_sizes=(1,), learning_rate=constant, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=sgd, score=0.848, total=   0.3s\n",
      "[CV] activation=logistic, batch_size=200, hidden_layer_sizes=(1,), learning_rate=constant, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=adam \n",
      "[CV]  activation=logistic, batch_size=200, hidden_layer_sizes=(1,), learning_rate=constant, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=adam, score=0.847, total=   0.2s\n",
      "[CV] activation=logistic, batch_size=200, hidden_layer_sizes=(1,), learning_rate=constant, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=adam \n",
      "[CV]  activation=logistic, batch_size=200, hidden_layer_sizes=(1,), learning_rate=constant, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=adam, score=0.848, total=   0.2s\n",
      "[CV] activation=logistic, batch_size=200, hidden_layer_sizes=(1,), learning_rate=constant, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=adam \n",
      "[CV]  activation=logistic, batch_size=200, hidden_layer_sizes=(1,), learning_rate=constant, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=adam, score=0.848, total=   0.2s\n",
      "[CV] activation=logistic, batch_size=200, hidden_layer_sizes=(1,), learning_rate=constant, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=adam \n",
      "[CV]  activation=logistic, batch_size=200, hidden_layer_sizes=(1,), learning_rate=constant, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=adam, score=0.848, total=   0.2s\n",
      "[CV] activation=logistic, batch_size=200, hidden_layer_sizes=(1,), learning_rate=constant, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=adam \n",
      "[CV]  activation=logistic, batch_size=200, hidden_layer_sizes=(1,), learning_rate=constant, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=adam, score=0.848, total=   0.2s\n",
      "[CV] activation=logistic, batch_size=200, hidden_layer_sizes=(1,), learning_rate=constant, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=sgd \n",
      "[CV]  activation=logistic, batch_size=200, hidden_layer_sizes=(1,), learning_rate=constant, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=sgd, score=0.847, total=   0.3s\n",
      "[CV] activation=logistic, batch_size=200, hidden_layer_sizes=(1,), learning_rate=constant, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=sgd \n",
      "[CV]  activation=logistic, batch_size=200, hidden_layer_sizes=(1,), learning_rate=constant, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=sgd, score=0.848, total=   0.3s\n",
      "[CV] activation=logistic, batch_size=200, hidden_layer_sizes=(1,), learning_rate=constant, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=sgd \n",
      "[CV]  activation=logistic, batch_size=200, hidden_layer_sizes=(1,), learning_rate=constant, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=sgd, score=0.848, total=   0.3s\n",
      "[CV] activation=logistic, batch_size=200, hidden_layer_sizes=(1,), learning_rate=constant, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=sgd \n",
      "[CV]  activation=logistic, batch_size=200, hidden_layer_sizes=(1,), learning_rate=constant, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=sgd, score=0.848, total=   0.3s\n",
      "[CV] activation=logistic, batch_size=200, hidden_layer_sizes=(1,), learning_rate=constant, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=sgd \n",
      "[CV]  activation=logistic, batch_size=200, hidden_layer_sizes=(1,), learning_rate=constant, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=sgd, score=0.848, total=   0.3s\n",
      "[CV] activation=logistic, batch_size=200, hidden_layer_sizes=(1,), learning_rate=constant, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=adam \n",
      "[CV]  activation=logistic, batch_size=200, hidden_layer_sizes=(1,), learning_rate=constant, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=adam, score=0.847, total=   0.6s\n",
      "[CV] activation=logistic, batch_size=200, hidden_layer_sizes=(1,), learning_rate=constant, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=adam \n",
      "[CV]  activation=logistic, batch_size=200, hidden_layer_sizes=(1,), learning_rate=constant, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=adam, score=0.848, total=   0.6s\n",
      "[CV] activation=logistic, batch_size=200, hidden_layer_sizes=(1,), learning_rate=constant, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=adam \n",
      "[CV]  activation=logistic, batch_size=200, hidden_layer_sizes=(1,), learning_rate=constant, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=adam, score=0.848, total=   0.6s\n",
      "[CV] activation=logistic, batch_size=200, hidden_layer_sizes=(1,), learning_rate=constant, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=adam \n",
      "[CV]  activation=logistic, batch_size=200, hidden_layer_sizes=(1,), learning_rate=constant, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=adam, score=0.848, total=   0.6s\n",
      "[CV] activation=logistic, batch_size=200, hidden_layer_sizes=(1,), learning_rate=constant, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=adam \n",
      "[CV]  activation=logistic, batch_size=200, hidden_layer_sizes=(1,), learning_rate=constant, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=adam, score=0.848, total=   0.6s\n",
      "[CV] activation=logistic, batch_size=200, hidden_layer_sizes=(1,), learning_rate=invscaling, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=sgd \n",
      "[CV]  activation=logistic, batch_size=200, hidden_layer_sizes=(1,), learning_rate=invscaling, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=sgd, score=0.847, total=   0.1s\n",
      "[CV] activation=logistic, batch_size=200, hidden_layer_sizes=(1,), learning_rate=invscaling, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=sgd \n",
      "[CV]  activation=logistic, batch_size=200, hidden_layer_sizes=(1,), learning_rate=invscaling, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=sgd, score=0.848, total=   0.1s\n",
      "[CV] activation=logistic, batch_size=200, hidden_layer_sizes=(1,), learning_rate=invscaling, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=sgd \n",
      "[CV]  activation=logistic, batch_size=200, hidden_layer_sizes=(1,), learning_rate=invscaling, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=sgd, score=0.848, total=   0.1s\n",
      "[CV] activation=logistic, batch_size=200, hidden_layer_sizes=(1,), learning_rate=invscaling, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=sgd \n",
      "[CV]  activation=logistic, batch_size=200, hidden_layer_sizes=(1,), learning_rate=invscaling, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=sgd, score=0.848, total=   0.1s\n",
      "[CV] activation=logistic, batch_size=200, hidden_layer_sizes=(1,), learning_rate=invscaling, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=sgd \n",
      "[CV]  activation=logistic, batch_size=200, hidden_layer_sizes=(1,), learning_rate=invscaling, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=sgd, score=0.848, total=   0.1s\n",
      "[CV] activation=logistic, batch_size=200, hidden_layer_sizes=(1,), learning_rate=invscaling, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=adam \n",
      "[CV]  activation=logistic, batch_size=200, hidden_layer_sizes=(1,), learning_rate=invscaling, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=adam, score=0.847, total=   0.2s\n",
      "[CV] activation=logistic, batch_size=200, hidden_layer_sizes=(1,), learning_rate=invscaling, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=adam \n",
      "[CV]  activation=logistic, batch_size=200, hidden_layer_sizes=(1,), learning_rate=invscaling, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=adam, score=0.848, total=   0.2s\n",
      "[CV] activation=logistic, batch_size=200, hidden_layer_sizes=(1,), learning_rate=invscaling, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=adam \n",
      "[CV]  activation=logistic, batch_size=200, hidden_layer_sizes=(1,), learning_rate=invscaling, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=adam, score=0.848, total=   0.2s\n",
      "[CV] activation=logistic, batch_size=200, hidden_layer_sizes=(1,), learning_rate=invscaling, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=adam \n",
      "[CV]  activation=logistic, batch_size=200, hidden_layer_sizes=(1,), learning_rate=invscaling, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=adam, score=0.848, total=   0.2s\n",
      "[CV] activation=logistic, batch_size=200, hidden_layer_sizes=(1,), learning_rate=invscaling, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=adam \n",
      "[CV]  activation=logistic, batch_size=200, hidden_layer_sizes=(1,), learning_rate=invscaling, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=adam, score=0.848, total=   0.2s\n",
      "[CV] activation=logistic, batch_size=200, hidden_layer_sizes=(1,), learning_rate=invscaling, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=sgd \n",
      "[CV]  activation=logistic, batch_size=200, hidden_layer_sizes=(1,), learning_rate=invscaling, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=sgd, score=0.153, total=   0.4s\n",
      "[CV] activation=logistic, batch_size=200, hidden_layer_sizes=(1,), learning_rate=invscaling, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=sgd \n",
      "[CV]  activation=logistic, batch_size=200, hidden_layer_sizes=(1,), learning_rate=invscaling, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=sgd, score=0.152, total=   0.4s\n",
      "[CV] activation=logistic, batch_size=200, hidden_layer_sizes=(1,), learning_rate=invscaling, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=sgd \n",
      "[CV]  activation=logistic, batch_size=200, hidden_layer_sizes=(1,), learning_rate=invscaling, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=sgd, score=0.152, total=   0.4s\n",
      "[CV] activation=logistic, batch_size=200, hidden_layer_sizes=(1,), learning_rate=invscaling, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=sgd \n",
      "[CV]  activation=logistic, batch_size=200, hidden_layer_sizes=(1,), learning_rate=invscaling, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=sgd, score=0.152, total=   0.4s\n",
      "[CV] activation=logistic, batch_size=200, hidden_layer_sizes=(1,), learning_rate=invscaling, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=sgd \n",
      "[CV]  activation=logistic, batch_size=200, hidden_layer_sizes=(1,), learning_rate=invscaling, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=sgd, score=0.152, total=   0.4s\n",
      "[CV] activation=logistic, batch_size=200, hidden_layer_sizes=(1,), learning_rate=invscaling, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=adam \n",
      "[CV]  activation=logistic, batch_size=200, hidden_layer_sizes=(1,), learning_rate=invscaling, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=adam, score=0.847, total=   0.6s\n",
      "[CV] activation=logistic, batch_size=200, hidden_layer_sizes=(1,), learning_rate=invscaling, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=adam \n",
      "[CV]  activation=logistic, batch_size=200, hidden_layer_sizes=(1,), learning_rate=invscaling, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=adam, score=0.848, total=   0.6s\n",
      "[CV] activation=logistic, batch_size=200, hidden_layer_sizes=(1,), learning_rate=invscaling, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=adam \n",
      "[CV]  activation=logistic, batch_size=200, hidden_layer_sizes=(1,), learning_rate=invscaling, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=adam, score=0.848, total=   0.6s\n",
      "[CV] activation=logistic, batch_size=200, hidden_layer_sizes=(1,), learning_rate=invscaling, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=adam \n",
      "[CV]  activation=logistic, batch_size=200, hidden_layer_sizes=(1,), learning_rate=invscaling, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=adam, score=0.848, total=   0.6s\n",
      "[CV] activation=logistic, batch_size=200, hidden_layer_sizes=(1,), learning_rate=invscaling, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=adam \n",
      "[CV]  activation=logistic, batch_size=200, hidden_layer_sizes=(1,), learning_rate=invscaling, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=adam, score=0.848, total=   0.6s\n",
      "[CV] activation=logistic, batch_size=200, hidden_layer_sizes=(1,), learning_rate=adaptive, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=sgd \n",
      "[CV]  activation=logistic, batch_size=200, hidden_layer_sizes=(1,), learning_rate=adaptive, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=sgd, score=0.847, total=   0.5s\n",
      "[CV] activation=logistic, batch_size=200, hidden_layer_sizes=(1,), learning_rate=adaptive, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=sgd \n",
      "[CV]  activation=logistic, batch_size=200, hidden_layer_sizes=(1,), learning_rate=adaptive, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=sgd, score=0.848, total=   0.6s\n",
      "[CV] activation=logistic, batch_size=200, hidden_layer_sizes=(1,), learning_rate=adaptive, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=sgd \n",
      "[CV]  activation=logistic, batch_size=200, hidden_layer_sizes=(1,), learning_rate=adaptive, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=sgd, score=0.850, total=   0.6s\n",
      "[CV] activation=logistic, batch_size=200, hidden_layer_sizes=(1,), learning_rate=adaptive, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=sgd \n",
      "[CV]  activation=logistic, batch_size=200, hidden_layer_sizes=(1,), learning_rate=adaptive, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=sgd, score=0.848, total=   0.6s\n",
      "[CV] activation=logistic, batch_size=200, hidden_layer_sizes=(1,), learning_rate=adaptive, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=sgd \n",
      "[CV]  activation=logistic, batch_size=200, hidden_layer_sizes=(1,), learning_rate=adaptive, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=sgd, score=0.848, total=   0.6s\n",
      "[CV] activation=logistic, batch_size=200, hidden_layer_sizes=(1,), learning_rate=adaptive, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=adam \n",
      "[CV]  activation=logistic, batch_size=200, hidden_layer_sizes=(1,), learning_rate=adaptive, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=adam, score=0.847, total=   0.2s\n",
      "[CV] activation=logistic, batch_size=200, hidden_layer_sizes=(1,), learning_rate=adaptive, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=adam \n",
      "[CV]  activation=logistic, batch_size=200, hidden_layer_sizes=(1,), learning_rate=adaptive, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=adam, score=0.848, total=   0.2s\n",
      "[CV] activation=logistic, batch_size=200, hidden_layer_sizes=(1,), learning_rate=adaptive, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=adam \n",
      "[CV]  activation=logistic, batch_size=200, hidden_layer_sizes=(1,), learning_rate=adaptive, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=adam, score=0.848, total=   0.2s\n",
      "[CV] activation=logistic, batch_size=200, hidden_layer_sizes=(1,), learning_rate=adaptive, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=adam \n",
      "[CV]  activation=logistic, batch_size=200, hidden_layer_sizes=(1,), learning_rate=adaptive, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=adam, score=0.848, total=   0.2s\n",
      "[CV] activation=logistic, batch_size=200, hidden_layer_sizes=(1,), learning_rate=adaptive, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=adam \n",
      "[CV]  activation=logistic, batch_size=200, hidden_layer_sizes=(1,), learning_rate=adaptive, learning_rate_init=0.1, max_iter=1000, random_state=4211, solver=adam, score=0.848, total=   0.2s\n",
      "[CV] activation=logistic, batch_size=200, hidden_layer_sizes=(1,), learning_rate=adaptive, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=sgd \n",
      "[CV]  activation=logistic, batch_size=200, hidden_layer_sizes=(1,), learning_rate=adaptive, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=sgd, score=0.847, total=   0.5s\n",
      "[CV] activation=logistic, batch_size=200, hidden_layer_sizes=(1,), learning_rate=adaptive, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=sgd \n",
      "[CV]  activation=logistic, batch_size=200, hidden_layer_sizes=(1,), learning_rate=adaptive, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=sgd, score=0.848, total=   0.5s\n",
      "[CV] activation=logistic, batch_size=200, hidden_layer_sizes=(1,), learning_rate=adaptive, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=sgd \n",
      "[CV]  activation=logistic, batch_size=200, hidden_layer_sizes=(1,), learning_rate=adaptive, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=sgd, score=0.848, total=   0.5s\n",
      "[CV] activation=logistic, batch_size=200, hidden_layer_sizes=(1,), learning_rate=adaptive, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=sgd \n",
      "[CV]  activation=logistic, batch_size=200, hidden_layer_sizes=(1,), learning_rate=adaptive, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=sgd, score=0.848, total=   0.5s\n",
      "[CV] activation=logistic, batch_size=200, hidden_layer_sizes=(1,), learning_rate=adaptive, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=sgd \n",
      "[CV]  activation=logistic, batch_size=200, hidden_layer_sizes=(1,), learning_rate=adaptive, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=sgd, score=0.848, total=   0.5s\n",
      "[CV] activation=logistic, batch_size=200, hidden_layer_sizes=(1,), learning_rate=adaptive, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=adam \n",
      "[CV]  activation=logistic, batch_size=200, hidden_layer_sizes=(1,), learning_rate=adaptive, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=adam, score=0.847, total=   0.6s\n",
      "[CV] activation=logistic, batch_size=200, hidden_layer_sizes=(1,), learning_rate=adaptive, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=adam \n",
      "[CV]  activation=logistic, batch_size=200, hidden_layer_sizes=(1,), learning_rate=adaptive, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=adam, score=0.848, total=   0.6s\n",
      "[CV] activation=logistic, batch_size=200, hidden_layer_sizes=(1,), learning_rate=adaptive, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=adam \n",
      "[CV]  activation=logistic, batch_size=200, hidden_layer_sizes=(1,), learning_rate=adaptive, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=adam, score=0.848, total=   0.6s\n",
      "[CV] activation=logistic, batch_size=200, hidden_layer_sizes=(1,), learning_rate=adaptive, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=adam \n",
      "[CV]  activation=logistic, batch_size=200, hidden_layer_sizes=(1,), learning_rate=adaptive, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=adam, score=0.848, total=   0.6s\n",
      "[CV] activation=logistic, batch_size=200, hidden_layer_sizes=(1,), learning_rate=adaptive, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=adam \n",
      "[CV]  activation=logistic, batch_size=200, hidden_layer_sizes=(1,), learning_rate=adaptive, learning_rate_init=0.001, max_iter=1000, random_state=4211, solver=adam, score=0.848, total=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 180 out of 180 | elapsed: 10.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV took 641.68 seconds for 36 candidate parameter settings.\n"
     ]
    }
   ],
   "source": [
    "# GridSearchCV\n",
    "sklmodel = MLPClassifier()\n",
    "sklmodelcv = GridSearchCV(sklmodel, grid_params, cv=5, verbose=3)\n",
    "start = time()\n",
    "sklmodelcv.fit(train_valid_x, train_valid_y)\n",
    "print(\"GridSearchCV took %.2f seconds for %d candidate parameter settings.\"\n",
    "  % (time() - start, len(sklmodelcv.cv_results_['params'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1162,
     "status": "ok",
     "timestamp": 1589610746704,
     "user": {
      "displayName": "onion bob",
      "photoUrl": "",
      "userId": "16615051757072184496"
     },
     "user_tz": -480
    },
    "id": "DWp4DUtL3uwi",
    "outputId": "4f835b97-07b3-4d0e-e077-d90e0075b28d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model cv saved to ==> ./Output/bestsklcv516.sav\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.848083 (std: 0.000933)\n",
      "Parameters: {'activation': 'logistic', 'batch_size': 32, 'hidden_layer_sizes': (1,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.1, 'max_iter': 1000, 'random_state': 4211, 'solver': 'sgd'}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.848083 (std: 0.000933)\n",
      "Parameters: {'activation': 'logistic', 'batch_size': 200, 'hidden_layer_sizes': (1,), 'learning_rate': 'constant', 'learning_rate_init': 0.1, 'max_iter': 1000, 'random_state': 4211, 'solver': 'sgd'}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.848083 (std: 0.000933)\n",
      "Parameters: {'activation': 'logistic', 'batch_size': 200, 'hidden_layer_sizes': (1,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.1, 'max_iter': 1000, 'random_state': 4211, 'solver': 'sgd'}\n",
      "\n",
      "Model with rank: 4\n",
      "Mean validation score: 0.847788 (std: 0.000590)\n",
      "Parameters: {'activation': 'logistic', 'batch_size': 4, 'hidden_layer_sizes': (1,), 'learning_rate': 'constant', 'learning_rate_init': 0.1, 'max_iter': 1000, 'random_state': 4211, 'solver': 'sgd'}\n",
      "\n",
      "Model with rank: 4\n",
      "Mean validation score: 0.847788 (std: 0.000590)\n",
      "Parameters: {'activation': 'logistic', 'batch_size': 4, 'hidden_layer_sizes': (1,), 'learning_rate': 'constant', 'learning_rate_init': 0.1, 'max_iter': 1000, 'random_state': 4211, 'solver': 'adam'}\n",
      "\n",
      "Model with rank: 4\n",
      "Mean validation score: 0.847788 (std: 0.000590)\n",
      "Parameters: {'activation': 'logistic', 'batch_size': 4, 'hidden_layer_sizes': (1,), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'max_iter': 1000, 'random_state': 4211, 'solver': 'sgd'}\n",
      "\n",
      "Model with rank: 4\n",
      "Mean validation score: 0.847788 (std: 0.000590)\n",
      "Parameters: {'activation': 'logistic', 'batch_size': 4, 'hidden_layer_sizes': (1,), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'max_iter': 1000, 'random_state': 4211, 'solver': 'adam'}\n",
      "\n",
      "Model with rank: 4\n",
      "Mean validation score: 0.847788 (std: 0.000590)\n",
      "Parameters: {'activation': 'logistic', 'batch_size': 4, 'hidden_layer_sizes': (1,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.1, 'max_iter': 1000, 'random_state': 4211, 'solver': 'sgd'}\n",
      "\n",
      "Model with rank: 4\n",
      "Mean validation score: 0.847788 (std: 0.000590)\n",
      "Parameters: {'activation': 'logistic', 'batch_size': 4, 'hidden_layer_sizes': (1,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.1, 'max_iter': 1000, 'random_state': 4211, 'solver': 'adam'}\n",
      "\n",
      "Model with rank: 4\n",
      "Mean validation score: 0.847788 (std: 0.000590)\n",
      "Parameters: {'activation': 'logistic', 'batch_size': 4, 'hidden_layer_sizes': (1,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.001, 'max_iter': 1000, 'random_state': 4211, 'solver': 'sgd'}\n",
      "\n",
      "Model with rank: 4\n",
      "Mean validation score: 0.847788 (std: 0.000590)\n",
      "Parameters: {'activation': 'logistic', 'batch_size': 4, 'hidden_layer_sizes': (1,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.001, 'max_iter': 1000, 'random_state': 4211, 'solver': 'adam'}\n",
      "\n",
      "Model with rank: 4\n",
      "Mean validation score: 0.847788 (std: 0.000590)\n",
      "Parameters: {'activation': 'logistic', 'batch_size': 4, 'hidden_layer_sizes': (1,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.1, 'max_iter': 1000, 'random_state': 4211, 'solver': 'sgd'}\n",
      "\n",
      "Model with rank: 4\n",
      "Mean validation score: 0.847788 (std: 0.000590)\n",
      "Parameters: {'activation': 'logistic', 'batch_size': 4, 'hidden_layer_sizes': (1,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.1, 'max_iter': 1000, 'random_state': 4211, 'solver': 'adam'}\n",
      "\n",
      "Model with rank: 4\n",
      "Mean validation score: 0.847788 (std: 0.000590)\n",
      "Parameters: {'activation': 'logistic', 'batch_size': 4, 'hidden_layer_sizes': (1,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_iter': 1000, 'random_state': 4211, 'solver': 'sgd'}\n",
      "\n",
      "Model with rank: 4\n",
      "Mean validation score: 0.847788 (std: 0.000590)\n",
      "Parameters: {'activation': 'logistic', 'batch_size': 4, 'hidden_layer_sizes': (1,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_iter': 1000, 'random_state': 4211, 'solver': 'adam'}\n",
      "\n",
      "Model with rank: 4\n",
      "Mean validation score: 0.847788 (std: 0.000590)\n",
      "Parameters: {'activation': 'logistic', 'batch_size': 32, 'hidden_layer_sizes': (1,), 'learning_rate': 'constant', 'learning_rate_init': 0.1, 'max_iter': 1000, 'random_state': 4211, 'solver': 'sgd'}\n",
      "\n",
      "Model with rank: 4\n",
      "Mean validation score: 0.847788 (std: 0.000590)\n",
      "Parameters: {'activation': 'logistic', 'batch_size': 32, 'hidden_layer_sizes': (1,), 'learning_rate': 'constant', 'learning_rate_init': 0.1, 'max_iter': 1000, 'random_state': 4211, 'solver': 'adam'}\n",
      "\n",
      "Model with rank: 4\n",
      "Mean validation score: 0.847788 (std: 0.000590)\n",
      "Parameters: {'activation': 'logistic', 'batch_size': 32, 'hidden_layer_sizes': (1,), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'max_iter': 1000, 'random_state': 4211, 'solver': 'sgd'}\n",
      "\n",
      "Model with rank: 4\n",
      "Mean validation score: 0.847788 (std: 0.000590)\n",
      "Parameters: {'activation': 'logistic', 'batch_size': 32, 'hidden_layer_sizes': (1,), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'max_iter': 1000, 'random_state': 4211, 'solver': 'adam'}\n",
      "\n",
      "Model with rank: 4\n",
      "Mean validation score: 0.847788 (std: 0.000590)\n",
      "Parameters: {'activation': 'logistic', 'batch_size': 32, 'hidden_layer_sizes': (1,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.1, 'max_iter': 1000, 'random_state': 4211, 'solver': 'sgd'}\n",
      "\n",
      "Model with rank: 4\n",
      "Mean validation score: 0.847788 (std: 0.000590)\n",
      "Parameters: {'activation': 'logistic', 'batch_size': 32, 'hidden_layer_sizes': (1,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.1, 'max_iter': 1000, 'random_state': 4211, 'solver': 'adam'}\n",
      "\n",
      "Model with rank: 4\n",
      "Mean validation score: 0.847788 (std: 0.000590)\n",
      "Parameters: {'activation': 'logistic', 'batch_size': 32, 'hidden_layer_sizes': (1,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.001, 'max_iter': 1000, 'random_state': 4211, 'solver': 'adam'}\n",
      "\n",
      "Model with rank: 4\n",
      "Mean validation score: 0.847788 (std: 0.000590)\n",
      "Parameters: {'activation': 'logistic', 'batch_size': 32, 'hidden_layer_sizes': (1,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.1, 'max_iter': 1000, 'random_state': 4211, 'solver': 'adam'}\n",
      "\n",
      "Model with rank: 4\n",
      "Mean validation score: 0.847788 (std: 0.000590)\n",
      "Parameters: {'activation': 'logistic', 'batch_size': 32, 'hidden_layer_sizes': (1,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_iter': 1000, 'random_state': 4211, 'solver': 'sgd'}\n",
      "\n",
      "Model with rank: 4\n",
      "Mean validation score: 0.847788 (std: 0.000590)\n",
      "Parameters: {'activation': 'logistic', 'batch_size': 32, 'hidden_layer_sizes': (1,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_iter': 1000, 'random_state': 4211, 'solver': 'adam'}\n",
      "\n",
      "Model with rank: 4\n",
      "Mean validation score: 0.847788 (std: 0.000590)\n",
      "Parameters: {'activation': 'logistic', 'batch_size': 200, 'hidden_layer_sizes': (1,), 'learning_rate': 'constant', 'learning_rate_init': 0.1, 'max_iter': 1000, 'random_state': 4211, 'solver': 'adam'}\n",
      "\n",
      "Model with rank: 4\n",
      "Mean validation score: 0.847788 (std: 0.000590)\n",
      "Parameters: {'activation': 'logistic', 'batch_size': 200, 'hidden_layer_sizes': (1,), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'max_iter': 1000, 'random_state': 4211, 'solver': 'sgd'}\n",
      "\n",
      "Model with rank: 4\n",
      "Mean validation score: 0.847788 (std: 0.000590)\n",
      "Parameters: {'activation': 'logistic', 'batch_size': 200, 'hidden_layer_sizes': (1,), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'max_iter': 1000, 'random_state': 4211, 'solver': 'adam'}\n",
      "\n",
      "Model with rank: 4\n",
      "Mean validation score: 0.847788 (std: 0.000590)\n",
      "Parameters: {'activation': 'logistic', 'batch_size': 200, 'hidden_layer_sizes': (1,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.1, 'max_iter': 1000, 'random_state': 4211, 'solver': 'sgd'}\n",
      "\n",
      "Model with rank: 4\n",
      "Mean validation score: 0.847788 (std: 0.000590)\n",
      "Parameters: {'activation': 'logistic', 'batch_size': 200, 'hidden_layer_sizes': (1,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.1, 'max_iter': 1000, 'random_state': 4211, 'solver': 'adam'}\n",
      "\n",
      "Model with rank: 4\n",
      "Mean validation score: 0.847788 (std: 0.000590)\n",
      "Parameters: {'activation': 'logistic', 'batch_size': 200, 'hidden_layer_sizes': (1,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.001, 'max_iter': 1000, 'random_state': 4211, 'solver': 'adam'}\n",
      "\n",
      "Model with rank: 4\n",
      "Mean validation score: 0.847788 (std: 0.000590)\n",
      "Parameters: {'activation': 'logistic', 'batch_size': 200, 'hidden_layer_sizes': (1,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.1, 'max_iter': 1000, 'random_state': 4211, 'solver': 'adam'}\n",
      "\n",
      "Model with rank: 4\n",
      "Mean validation score: 0.847788 (std: 0.000590)\n",
      "Parameters: {'activation': 'logistic', 'batch_size': 200, 'hidden_layer_sizes': (1,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_iter': 1000, 'random_state': 4211, 'solver': 'sgd'}\n",
      "\n",
      "Model with rank: 4\n",
      "Mean validation score: 0.847788 (std: 0.000590)\n",
      "Parameters: {'activation': 'logistic', 'batch_size': 200, 'hidden_layer_sizes': (1,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_iter': 1000, 'random_state': 4211, 'solver': 'adam'}\n",
      "\n",
      "Model with rank: 35\n",
      "Mean validation score: 0.817699 (std: 0.005796)\n",
      "Parameters: {'activation': 'logistic', 'batch_size': 32, 'hidden_layer_sizes': (1,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.001, 'max_iter': 1000, 'random_state': 4211, 'solver': 'sgd'}\n",
      "\n",
      "Model with rank: 36\n",
      "Mean validation score: 0.152212 (std: 0.000590)\n",
      "Parameters: {'activation': 'logistic', 'batch_size': 200, 'hidden_layer_sizes': (1,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.001, 'max_iter': 1000, 'random_state': 4211, 'solver': 'sgd'}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'activation': 'logistic',\n",
       " 'batch_size': 32,\n",
       " 'hidden_layer_sizes': (1,),\n",
       " 'learning_rate': 'adaptive',\n",
       " 'learning_rate_init': 0.1,\n",
       " 'max_iter': 1000,\n",
       " 'random_state': 4211,\n",
       " 'solver': 'sgd'}"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Output of the model ranks and scores and return the best model params\n",
    "sklcv_save_path = save_output + '/bestsklcv516.sav'\n",
    "pickle.dump(sklmodelcv, open(sklcv_save_path, 'wb'))\n",
    "print(f'Model cv saved to ==> {sklcv_save_path}')\n",
    "\n",
    "best_skl_params = report(sklmodelcv.cv_results_)\n",
    "best_skl_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CS1QDZt4TFS5"
   },
   "source": [
    "### **Model Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OWf-DqjNW5t6"
   },
   "outputs": [],
   "source": [
    "# Model Training Function\n",
    "def skltrain(model, inputs, labels, val_inputs, val_labels, save_path):\n",
    "    start = time()\n",
    "    model.fit(inputs, labels)\n",
    "    train_time = time() - start\n",
    "    pred = model.predict(val_inputs)\n",
    "    train_loss = model.loss_\n",
    "    train_acc = accuracy_score(val_labels, pred)\n",
    "    train_f1 = f1_score(val_labels, pred, average='weighted')\n",
    "    print('Training time:', train_time)\n",
    "    print('Loss:', train_loss)\n",
    "    print('Accuracy:', train_acc)\n",
    "    print('F1 score:', train_f1)\n",
    "    print(classification_report(val_labels, pred))\n",
    "\n",
    "    pickle.dump(model, open(save_path, 'wb'))\n",
    "    print(f'Model saved to ==> {save_path}')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 488
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2975,
     "status": "ok",
     "timestamp": 1589611077407,
     "user": {
      "displayName": "onion bob",
      "photoUrl": "",
      "userId": "16615051757072184496"
     },
     "user_tz": -480
    },
    "id": "oQEehOWZaYn_",
    "outputId": "0a99d49b-fc62-45be-ea01-4143bdb1a36d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier(activation='logistic', alpha=0.0001, batch_size=32, beta_1=0.9,\n",
      "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "              hidden_layer_sizes=(1,), learning_rate='adaptive',\n",
      "              learning_rate_init=0.1, max_fun=15000, max_iter=1000,\n",
      "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
      "              power_t=0.5, random_state=4211, shuffle=True, solver='sgd',\n",
      "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "              warm_start=False)\n",
      "Training time: 1.6305804252624512\n",
      "Loss: 0.3818790162515369\n",
      "Accuracy: 0.8480825958702065\n",
      "F1 score: 0.7783679052280427\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      1.00      0.92       575\n",
      "         1.0       0.00      0.00      0.00       103\n",
      "\n",
      "    accuracy                           0.85       678\n",
      "   macro avg       0.42      0.50      0.46       678\n",
      "weighted avg       0.72      0.85      0.78       678\n",
      "\n",
      "Model saved to ==> ./Output/bestsklmodel516.sav\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Training with validation set\n",
    "skl_save_path = save_output + '/bestsklmodel516.sav'\n",
    "sklmodel = MLPClassifier(**best_skl_params)\n",
    "print(sklmodel)\n",
    "skltrain(sklmodel, train_x, train_y, valid_x, valid_y, skl_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g3zRq7KNTI8K"
   },
   "source": [
    "### **Load Model for Test Set and Metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EX0sHAHkcMLT"
   },
   "outputs": [],
   "source": [
    "# Load the model\n",
    "skl_load_save_path = save_output + '/bestsklmodel516.sav'\n",
    "skl_load_model = pickle.load(open(skl_load_save_path, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3706,
     "status": "ok",
     "timestamp": 1589700156999,
     "user": {
      "displayName": "onion bob",
      "photoUrl": "",
      "userId": "16615051757072184496"
     },
     "user_tz": -480
    },
    "id": "lv_XggGVNkeX",
    "outputId": "cca95298-e754-418a-ef21-10a06010ebd3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 1.8701131343841553\n",
      "Loss: 0.38173440159761163\n",
      "Accuracy: 0.8514150943396226\n",
      "F1 score: 0.7853861168109704\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      1.00      0.92       720\n",
      "         1.0       1.00      0.02      0.03       128\n",
      "\n",
      "    accuracy                           0.85       848\n",
      "   macro avg       0.93      0.51      0.48       848\n",
      "weighted avg       0.87      0.85      0.79       848\n",
      "\n",
      "Model saved to ==> ./Output/bestsklmodel516.sav\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use the loaded model to train with test set\n",
    "skltrain(skl_load_model, train_valid_x, train_valid_y, test_x, test_y, skl_load_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1860,
     "status": "ok",
     "timestamp": 1589699985011,
     "user": {
      "displayName": "onion bob",
      "photoUrl": "",
      "userId": "16615051757072184496"
     },
     "user_tz": -480
    },
    "id": "OVVktAuMfbdu",
    "outputId": "0436bba7-2b3c-4582-96ad-2a18d903ad18"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f578e6c4358>"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Confusion Matrix of Test Set\n",
    "plot_confusion_matrix(skl_load_model, test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1932,
     "status": "ok",
     "timestamp": 1589699529139,
     "user": {
      "displayName": "onion bob",
      "photoUrl": "",
      "userId": "16615051757072184496"
     },
     "user_tz": -480
    },
    "id": "ymbHYY7zMWw7",
    "outputId": "42483a03-803b-4702-cddd-31138fdd12d5"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the loss curve\n",
    "plt.plot(skl_load_model.loss_curve_)\n",
    "plt.title('Loss Curve of Sklearn Model with Test Set Evaluated')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Number of iterations')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2539,
     "status": "ok",
     "timestamp": 1589701229469,
     "user": {
      "displayName": "onion bob",
      "photoUrl": "",
      "userId": "16615051757072184496"
     },
     "user_tz": -480
    },
    "id": "sRAAiq3Kjv50",
    "outputId": "f1f289b9-13fa-496d-c60e-9497173f85ce"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "male              -0.460927\n",
       "age               -2.768042\n",
       "education          0.071125\n",
       "currentSmoker     -0.052116\n",
       "cigsPerDay        -1.466586\n",
       "BPMeds            -0.398074\n",
       "prevalentStroke   -0.662966\n",
       "prevalentHyp      -0.233244\n",
       "diabetes          -0.761455\n",
       "totChol           -0.870188\n",
       "sysBP             -2.522399\n",
       "diaBP             -0.333406\n",
       "BMI               -0.437024\n",
       "heartRate          0.226464\n",
       "glucose           -1.190203\n",
       "TenYearCHD        -4.230272\n",
       "Name: 0, dtype: float64"
      ]
     },
     "execution_count": 50,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Weights of each feature for coherance of observation\n",
    "sklweight = np.append(skl_load_model.coefs_[0].squeeze(), skl_load_model.coefs_[1].squeeze())\n",
    "sklweightdf = df.iloc[0, :]\n",
    "sklweightdf.iloc[:] = sklweight\n",
    "sklweightdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hmYI9zOKdNew"
   },
   "source": [
    "## **Pytorch Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NHkqbthUdIQC"
   },
   "source": [
    "### **Dataset and Dataloader**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XffGRxsVcJ3_"
   },
   "outputs": [],
   "source": [
    "# Custom dataset\n",
    "class heartDiseaseDataset(Dataset):\n",
    "\n",
    "    def __init__(self,  csv):\n",
    "        self.df = csv\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        #column 0 to 14 is the feature\n",
    "        feature = self.df.iloc[idx, 0:15].astype('float').values \n",
    "        feature = np.array([feature])\n",
    "        #column 15 is the target\n",
    "        label = self.df.iloc[idx, 15]\n",
    "        label = np.array([label])\n",
    "        label = np.squeeze(label)\n",
    "        return feature, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1926,
     "status": "ok",
     "timestamp": 1589731297272,
     "user": {
      "displayName": "Hoshi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgvJ9tk-7YVwMuT4roRhSvIVbF7D-gcIePVxYIukw=s64",
      "userId": "16228246563220513239"
     },
     "user_tz": -480
    },
    "id": "249mpMIfgvXH",
    "outputId": "56503c01-2771-4cb6-ff20-13f498dffb26"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batched features:\n",
      " tensor([[[0.0000, 0.4474, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.3362, 0.2435, 0.4339, 0.2302, 0.1818, 0.2175]],\n",
      "\n",
      "        [[0.0000, 0.5000, 0.6667, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.1817, 0.2624, 0.4762, 0.3456, 0.2323, 0.1186]],\n",
      "\n",
      "        [[1.0000, 0.2368, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.1494, 0.2624, 0.4233, 0.2748, 0.4141, 0.0706]],\n",
      "\n",
      "        [[0.0000, 0.8421, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.3362, 0.2033, 0.2011, 0.2479, 0.2323, 0.0734]],\n",
      "\n",
      "        [[1.0000, 0.1842, 0.0000, 1.0000, 0.5714, 0.0000, 0.0000, 1.0000,\n",
      "          0.0000, 0.1834, 0.2931, 0.4709, 0.3105, 0.3131, 0.1525]],\n",
      "\n",
      "        [[1.0000, 0.5526, 0.6667, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.2479, 0.1489, 0.3492, 0.3042, 0.2626, 0.1243]],\n",
      "\n",
      "        [[1.0000, 0.6053, 0.0000, 1.0000, 0.0857, 0.0000, 0.0000, 1.0000,\n",
      "          0.0000, 0.2835, 0.3050, 0.4868, 0.3153, 0.1818, 0.0706]],\n",
      "\n",
      "        [[1.0000, 0.4211, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000,\n",
      "          0.0000, 0.3158, 0.3097, 0.5503, 0.3895, 0.4343, 0.1017]],\n",
      "\n",
      "        [[0.0000, 0.2105, 0.3333, 1.0000, 0.1286, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.1460, 0.1017, 0.1270, 0.1697, 0.3131, 0.1271]],\n",
      "\n",
      "        [[1.0000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000,\n",
      "          0.0000, 0.1664, 0.1962, 0.4868, 0.3289, 0.2828, 0.1412]],\n",
      "\n",
      "        [[1.0000, 0.5526, 0.3333, 1.0000, 0.2857, 0.0000, 0.0000, 1.0000,\n",
      "          0.0000, 0.2699, 0.3759, 0.6032, 0.3030, 0.4646, 0.1102]],\n",
      "\n",
      "        [[1.0000, 0.5263, 0.6667, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.2003, 0.1678, 0.1799, 0.2751, 0.1818, 0.0960]],\n",
      "\n",
      "        [[1.0000, 0.3158, 0.3333, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000,\n",
      "          0.0000, 0.2054, 0.4468, 0.7937, 0.3880, 0.3434, 0.1186]],\n",
      "\n",
      "        [[0.0000, 0.7368, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.2886, 0.2009, 0.2328, 0.2324, 0.1616, 0.1695]],\n",
      "\n",
      "        [[0.0000, 0.0526, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.1392, 0.1158, 0.1905, 0.1277, 0.3434, 0.1356]],\n",
      "\n",
      "        [[1.0000, 0.5263, 0.6667, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000,\n",
      "          0.0000, 0.2122, 0.3333, 0.4656, 0.2659, 0.4646, 0.0960]],\n",
      "\n",
      "        [[0.0000, 0.2895, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000,\n",
      "          0.0000, 0.1749, 0.2600, 0.5026, 0.1830, 0.3131, 0.1186]],\n",
      "\n",
      "        [[0.0000, 0.4474, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.1715, 0.0591, 0.1587, 0.1246, 0.2121, 0.1638]],\n",
      "\n",
      "        [[0.0000, 0.3684, 0.0000, 1.0000, 0.2857, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.1630, 0.1584, 0.2116, 0.1444, 0.6667, 0.1271]],\n",
      "\n",
      "        [[1.0000, 0.1579, 0.3333, 1.0000, 0.2857, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.1239, 0.1868, 0.2222, 0.1735, 0.2828, 0.0847]],\n",
      "\n",
      "        [[0.0000, 0.4211, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.1460, 0.2600, 0.4180, 0.2317, 0.2020, 0.1412]],\n",
      "\n",
      "        [[0.0000, 0.6053, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.1494, 0.2364, 0.3545, 0.1920, 0.4646, 0.1186]],\n",
      "\n",
      "        [[0.0000, 0.2105, 0.0000, 1.0000, 0.2857, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.1358, 0.1111, 0.2751, 0.1655, 0.1616, 0.0763]],\n",
      "\n",
      "        [[1.0000, 0.4211, 0.3333, 1.0000, 0.5714, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.2377, 0.2340, 0.3122, 0.4472, 0.3737, 0.1554]],\n",
      "\n",
      "        [[1.0000, 0.2895, 1.0000, 1.0000, 0.2857, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.1358, 0.2175, 0.4233, 0.2443, 0.3636, 0.0989]],\n",
      "\n",
      "        [[1.0000, 0.2632, 0.3333, 1.0000, 0.2857, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.1647, 0.1253, 0.2646, 0.1983, 0.1616, 0.0989]],\n",
      "\n",
      "        [[1.0000, 0.3684, 1.0000, 1.0000, 0.2857, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.2581, 0.0827, 0.2434, 0.1105, 0.3636, 0.0932]],\n",
      "\n",
      "        [[1.0000, 0.6579, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.1205, 0.1868, 0.3280, 0.2622, 0.3030, 0.1073]],\n",
      "\n",
      "        [[0.0000, 0.7105, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.4041, 0.3050, 0.4974, 0.1983, 0.3535, 0.0565]],\n",
      "\n",
      "        [[0.0000, 0.2368, 0.3333, 1.0000, 0.2000, 0.0000, 0.0000, 1.0000,\n",
      "          0.0000, 0.1375, 0.2908, 0.5397, 0.3165, 0.4141, 0.0960]],\n",
      "\n",
      "        [[0.0000, 0.8158, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000,\n",
      "          0.0000, 0.2207, 0.3381, 0.4709, 0.3868, 0.1818, 0.1215]],\n",
      "\n",
      "        [[1.0000, 0.2368, 0.3333, 1.0000, 0.5714, 0.0000, 0.0000, 1.0000,\n",
      "          0.0000, 0.3497, 0.1442, 0.3280, 0.2445, 0.1616, 0.1497]]],\n",
      "       dtype=torch.float64),       \n",
      " Batched labels:\n",
      " tensor([0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "       dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# Load the data into the dataloader\n",
    "# Set the num_worker to a lower value and delete the pin_memory = True if you are not on GPU\n",
    "batch_size = 32\n",
    "train_set = heartDiseaseDataset(train)\n",
    "valid_set = heartDiseaseDataset(valid)\n",
    "test_set = heartDiseaseDataset(test)\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size,\n",
    "                          shuffle=True, num_workers=16,pin_memory=True)\n",
    "\n",
    "valid_loader = DataLoader(valid_set, batch_size=batch_size,\n",
    "                          shuffle=True, num_workers=16,pin_memory=True)\n",
    "\n",
    "test_loader = DataLoader(test_set, batch_size=1,\n",
    "                         shuffle=True, num_workers=16,pin_memory=True)\n",
    "# Just a test see whether the dataloader and custom dataset class wordks or not(not related to the model)\n",
    "dataiter = iter(train_loader)\n",
    "inputs, labels = dataiter.next()\n",
    "\n",
    "print(f'Batched features:\\n {inputs}, \\\n",
    "      \\n Batched labels:\\n {labels}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q6fpgIcze4o1"
   },
   "source": [
    "### **Model Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QXAoHnSXPiQL"
   },
   "outputs": [],
   "source": [
    "# Save Load function\n",
    "def save_average(save_path, average_train_loss, average_val_loss, average_train_acc, average_val_acc, average_train_f1, average_val_f1):\n",
    "    if save_path==None:\n",
    "        return\n",
    "    save_path = save_path \n",
    "    state_dict = {'average_train_loss': average_train_loss,\n",
    "                  'average_val_loss': average_val_loss,\n",
    "                  'average_train_acc': average_train_acc,\n",
    "                  'average_val_acc': average_val_acc,\n",
    "                  'average_train_f1': average_train_f1,\n",
    "                  'average_val_f1': average_val_f1}\n",
    "    torch.save(state_dict, save_path)\n",
    "    print(f'Model average saved to ==> {save_path}')\n",
    "    \n",
    "def load_average(save_path):\n",
    "    try:\n",
    "        state_dict = torch.load(save_path)\n",
    "        print(f'Model average loaded from <== {save_path}')\n",
    "        return state_dict['average_train_loss'], state_dict['average_val_loss'], state_dict['average_train_acc'], state_dict['average_val_acc'], state_dict['average_train_f1'], state_dict['average_val_f1']\n",
    "    except: # pass anyway\n",
    "        return [], [], [], [], [], []\n",
    "    \n",
    "def save_value(save_path, train_loss, train_acc, train_f1, train_time, validation_loss, validation_acc, validation_f1, validation_time):\n",
    "    if save_path==None:\n",
    "        return\n",
    "    save_path = save_path \n",
    "    state_dict = {'train_loss': train_loss,\n",
    "                  'train_acc': train_acc,\n",
    "                  'train_f1': train_f1,\n",
    "                  'train_time': train_time,\n",
    "                  'validation_loss': validation_loss,\n",
    "                  'validation_acc': validation_acc,\n",
    "                  'validation_f1': validation_f1,\n",
    "                  'validation_time': validation_time}\n",
    "    torch.save(state_dict, save_path)\n",
    "    print(f'Model value saved to ==> {save_path}')\n",
    "    \n",
    "def load_value(save_path):\n",
    "    try:\n",
    "        state_dict = torch.load(save_path)\n",
    "        print(f'Model value loaded from <== {save_path}')\n",
    "        return state_dict['train_loss'], state_dict['train_acc'], state_dict['train_f1'], state_dict['train_time'], state_dict['validation_loss'], state_dict['validation_acc'], state_dict['validation_f1'], state_dict['validation_time']\n",
    "    except: # pass anyway\n",
    "        return [], [], [], [], [], [], [], []\n",
    "    \n",
    "\n",
    "def save_checkpoint(save_path, model, optimizer, val_loss, latest):\n",
    "    if save_path==None:\n",
    "        return\n",
    "    save_path = save_path \n",
    "    state_dict = {'model_state_dict': model.state_dict(),\n",
    "                  'optimizer_state_dict': optimizer.state_dict(),\n",
    "                  'val_loss': val_loss,\n",
    "                  'latest': latest,\n",
    "                  'model': model,\n",
    "                  'optimizer': optimizer}\n",
    "\n",
    "    torch.save(state_dict, save_path)\n",
    "\n",
    "    print(f'Model saved to ==> {save_path}')\n",
    "    \n",
    "def load_checkpoint(model, optimizer, save_path):\n",
    "    state_dict = torch.load(save_path)\n",
    "    \n",
    "    try:\n",
    "        model = state_dict['model']\n",
    "        optimizer = state_dict['optimizer']\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    model.load_state_dict(state_dict['model_state_dict'])\n",
    "    optimizer.load_state_dict(state_dict['optimizer_state_dict'])\n",
    "    val_loss = state_dict['val_loss']\n",
    "    print(f'Model loaded from <== {save_path}')\n",
    "    \n",
    "    try:\n",
    "        return val_loss, state_dict['latest'], model, optimizer\n",
    "    except:\n",
    "        return val_loss, [], model, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BF7pfPu44PYg"
   },
   "outputs": [],
   "source": [
    "# Training Function\n",
    "def TRAIN(net, train_loader, valid_loader,  num_epochs, eval_every, total_step, criterion, optimizer, val_loss, device, save_path):\n",
    "    \n",
    "    \n",
    "    # Other record method\n",
    "    train_loss = [] # 1 result per batch_size\n",
    "    train_acc = []\n",
    "    train_f1 = []\n",
    "    train_time = []\n",
    "    validation_loss = []\n",
    "    validation_acc = []\n",
    "    validation_f1 = []\n",
    "    validation_time = []\n",
    "    avg_train_loss = []   # 1 result per eval_every*batch_size\n",
    "    avg_train_acc = []\n",
    "    avg_train_f1 = []\n",
    "    avg_val_loss = []\n",
    "    avg_val_acc = []\n",
    "    avg_val_f1 = []\n",
    "    save_path2 = save_path + 'v'\n",
    "    save_path3 = save_path + 'a'\n",
    "    \n",
    "    global_step = 0\n",
    "    if val_loss==None:\n",
    "        best_val_loss = float(\"Inf\")  \n",
    "    else: \n",
    "        best_val_loss=val_loss\n",
    "        train_loss, train_acc, train_f1, train_time, validation_loss, validation_acc, validation_f1, validation_time = load_value(save_path2)\n",
    "        avg_train_loss, avg_val_loss, avg_train_acc, avg_val_acc, avg_train_f1, avg_val_f1 = load_average(save_path3)\n",
    "    \n",
    "\n",
    "    for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "        \n",
    "        # Initialization\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "        running_f1 = 0.0\n",
    "        running_num = 0\n",
    "\n",
    "        for i, (inputs, labels) in enumerate(train_loader):\n",
    "\n",
    "            net.train()\n",
    "            inputs = inputs.to(device).float()\n",
    "            labels = labels.to(device).float()\n",
    "            #print(inputs)\n",
    "\n",
    "            '''Training of the model'''\n",
    "            # Forward pass\n",
    "            starttime = time()\n",
    "            outputs = net(inputs)\n",
    "            outputs = outputs.squeeze()\n",
    "            train_time.append(time() - starttime)\n",
    "            ##print(outputs)\n",
    "            \n",
    "            # Prediction\n",
    "            threshold = torch.tensor([0.285]).to(device)\n",
    "            pred = (outputs>threshold).to(device).int()\n",
    "            pred = pred.squeeze().float()\n",
    "\n",
    "            # Loss\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            global_step += 1\n",
    "\n",
    "            # Metrics calculation\n",
    "            batch_corrects = 0.0\n",
    "            running_loss += loss.item()\n",
    "            for i in range(0, len(pred)):\n",
    "                batch_corrects += torch.equal(pred[i], labels[i])\n",
    "                running_corrects += torch.equal(pred[i], labels[i])\n",
    "            running_f1 += f1_score(labels.cpu(), pred.cpu(), average='weighted')\n",
    "            running_num += len(labels)\n",
    "\n",
    "            # Other record method\n",
    "            train_loss.append(loss.item())\n",
    "            train_acc.append(batch_corrects / len(labels))\n",
    "            train_f1.append(f1_score(labels.cpu(), pred.cpu(), average='weighted'))\n",
    "\n",
    "            '''Evaluating the model every x steps'''\n",
    "            if global_step % eval_every == 0:\n",
    "                with torch.no_grad():\n",
    "                    net.eval()\n",
    "                    val_running_loss = 0.0\n",
    "                    val_running_corrects = 0\n",
    "                    val_running_f1 = 0.0\n",
    "                    val_running_num = 0\n",
    "\n",
    "                    for val_inputs, val_labels in valid_loader:\n",
    "                        val_inputs = val_inputs.to(device).float()\n",
    "                        val_labels = val_labels.to(device).float()\n",
    "\n",
    "                        # Forward pass\n",
    "                        val_starttime = time()\n",
    "                        val_outputs = net(val_inputs)\n",
    "                        val_outputs = val_outputs.squeeze()\n",
    "                        validation_time.append(time() - val_starttime)\n",
    "\n",
    "                        # Prediction\n",
    "                        threshold = torch.tensor([0.285]).to(device)\n",
    "                        val_pred= (val_outputs>threshold).to(device).int()\n",
    "                        val_pred = val_pred.squeeze().float()\n",
    "                        #print(val_outputs)\n",
    "\n",
    "                        # Loss\n",
    "                        val_loss = criterion(val_outputs, val_labels)\n",
    "                        \n",
    "                        # Metrics calculation\n",
    "                        val_batch_corrects = 0.0\n",
    "                        val_running_loss += val_loss.item()\n",
    "                        for i in range(0, len(val_pred)):\n",
    "                            val_batch_corrects += torch.equal(val_pred[i], val_labels[i])\n",
    "                            val_running_corrects += torch.equal(val_pred[i], val_labels[i])\n",
    "                        val_running_f1 += f1_score(val_labels.cpu(), val_pred.cpu(), average='weighted')\n",
    "                        val_running_num += len(val_labels)\n",
    "\n",
    "                        # Other record method\n",
    "                        validation_loss.append(val_loss.item())\n",
    "                        validation_acc.append(val_batch_corrects / len(val_labels))\n",
    "                        validation_f1.append(f1_score(val_labels.cpu(), val_pred.cpu(), average='weighted'))\n",
    "                        \n",
    "                        \n",
    "                    # Showing the metrics\n",
    "                    average_train_loss = running_loss / eval_every\n",
    "                    average_val_loss = val_running_loss / len(valid_loader)\n",
    "                    average_train_acc = running_corrects / float(running_num)\n",
    "                    average_val_acc = val_running_corrects / float(val_running_num)\n",
    "                    average_train_f1 = running_f1 / eval_every\n",
    "                    average_val_f1 = val_running_f1 / len(valid_loader)\n",
    "\n",
    "                    # Other record method\n",
    "                    avg_train_loss.append(average_train_loss)\n",
    "                    avg_val_loss.append(average_val_loss)\n",
    "                    avg_train_acc.append(average_train_acc)\n",
    "                    avg_val_acc.append(average_val_acc)\n",
    "                    avg_train_f1.append(average_train_f1)\n",
    "                    avg_val_f1.append(average_val_f1)\n",
    "\n",
    "                    # ...log the running loss\n",
    "                    writer.add_scalar(\n",
    "                        f'training loss {num_epochs}', average_train_loss, global_step)\n",
    "\n",
    "                    # ...log the running loss\n",
    "                    writer.add_scalar(\n",
    "                        f'validation loss {num_epochs}', average_val_loss, global_step)\n",
    "                    \n",
    "                    # ...log the running acc\n",
    "                    writer.add_scalar(\n",
    "                        f'training accuracy {num_epochs}', average_train_acc, global_step)\n",
    "\n",
    "                    # ...log the running acc\n",
    "                    writer.add_scalar(\n",
    "                        f'validation accuracy {num_epochs}', average_val_acc, global_step)\n",
    "                    \n",
    "                    # ...log the running f1\n",
    "                    writer.add_scalar(\n",
    "                        f'training f1 {num_epochs}', average_train_f1, global_step)\n",
    "\n",
    "                    # ...log the running f1\n",
    "                    writer.add_scalar(\n",
    "                        f'validation f1 {num_epochs}', average_val_f1, global_step)\n",
    "                    \n",
    "                    print('Epoch [{}/{}], Step [{}/{}], Train Loss: {:.6f}, Train Acc: {:.6f}, Train F1: {:.6f}, Valid Loss: {:.6f}, Valid Acc: {:.6f},  Valid F1: {:.6f}'\n",
    "                          .format(epoch+1, num_epochs, global_step, total_step, average_train_loss,\n",
    "                                  average_train_acc, average_train_f1, average_val_loss, average_val_acc, average_val_f1))\n",
    "                    \n",
    "                    # Reset the metrics for average_mertics\n",
    "                    running_loss = 0.0\n",
    "                    running_corrects = 0\n",
    "                    running_f1 = 0.0\n",
    "                    running_num = 0 \n",
    "                    \n",
    "                    # Record the average\n",
    "                    save_average(save_path3, avg_train_loss, avg_val_loss, avg_train_acc, avg_val_acc, avg_train_f1, avg_val_f1)\n",
    "                    \n",
    "                    if average_val_loss < best_val_loss:\n",
    "                        best_val_loss = average_val_loss\n",
    "                        save_checkpoint(save_path, net, optimizer, best_val_loss, False)\n",
    "                    \n",
    "         # Record all value after each epoch\n",
    "        save_value(save_path2, train_loss, train_acc, train_f1, train_time, validation_loss, validation_acc, validation_f1, validation_time)                \n",
    "        save_checkpoint(save_path + '_latest', net, optimizer, best_val_loss, True)\n",
    "                    \n",
    "    print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UtYONCZY3Muw"
   },
   "outputs": [],
   "source": [
    "# Model architecture\n",
    "class LogisticReg(torch.nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LogisticReg, self).__init__()\n",
    "        self.linear = torch.nn.Linear(input_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        outputs = torch.sigmoid(self.linear(x))\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M9vk_BlGhJiq"
   },
   "outputs": [],
   "source": [
    "# Print model achitecture and total number of parameters\n",
    "def count_parameters(model):\n",
    "    temp = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f'The model architecture:\\n\\n', model)\n",
    "    print(f'\\nThe model has {temp:,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1477,
     "status": "ok",
     "timestamp": 1589731306799,
     "user": {
      "displayName": "Hoshi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgvJ9tk-7YVwMuT4roRhSvIVbF7D-gcIePVxYIukw=s64",
      "userId": "16228246563220513239"
     },
     "user_tz": -480
    },
    "id": "0r1sCk6ECmMO",
    "outputId": "50b37d86-412c-4721-b734-3d3f249e6d55"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.4657]],\n",
       "\n",
       "        [[0.4616]],\n",
       "\n",
       "        [[0.5043]],\n",
       "\n",
       "        [[0.4696]],\n",
       "\n",
       "        [[0.5274]],\n",
       "\n",
       "        [[0.5133]],\n",
       "\n",
       "        [[0.5425]],\n",
       "\n",
       "        [[0.5470]],\n",
       "\n",
       "        [[0.4425]],\n",
       "\n",
       "        [[0.5389]],\n",
       "\n",
       "        [[0.5309]],\n",
       "\n",
       "        [[0.5198]],\n",
       "\n",
       "        [[0.5606]],\n",
       "\n",
       "        [[0.4697]],\n",
       "\n",
       "        [[0.4481]],\n",
       "\n",
       "        [[0.5423]],\n",
       "\n",
       "        [[0.4821]],\n",
       "\n",
       "        [[0.4540]],\n",
       "\n",
       "        [[0.4288]],\n",
       "\n",
       "        [[0.4952]],\n",
       "\n",
       "        [[0.4581]],\n",
       "\n",
       "        [[0.4493]],\n",
       "\n",
       "        [[0.4393]],\n",
       "\n",
       "        [[0.5030]],\n",
       "\n",
       "        [[0.4925]],\n",
       "\n",
       "        [[0.4974]],\n",
       "\n",
       "        [[0.4916]],\n",
       "\n",
       "        [[0.5074]],\n",
       "\n",
       "        [[0.4623]],\n",
       "\n",
       "        [[0.4709]],\n",
       "\n",
       "        [[0.5028]],\n",
       "\n",
       "        [[0.5341]]], grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 422,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A test on the output value of the logisticregression network\n",
    "model = LogisticReg(15,1)\n",
    "output = model(inputs.float())\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 144
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 753,
     "status": "ok",
     "timestamp": 1589731308087,
     "user": {
      "displayName": "Hoshi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgvJ9tk-7YVwMuT4roRhSvIVbF7D-gcIePVxYIukw=s64",
      "userId": "16228246563220513239"
     },
     "user_tz": -480
    },
    "id": "Kj88JX8d8MXD",
    "outputId": "bb5d6ff7-75aa-484b-f59a-808bdc7b0f9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model architecture:\n",
      "\n",
      " LogisticReg(\n",
      "  (linear): Linear(in_features=15, out_features=1, bias=True)\n",
      ")\n",
      "\n",
      "The model has 16 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "# Showing the parameters\n",
    "device = 'cuda'\n",
    "model = LogisticReg(15, 1).to(device)\n",
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xc8lMaE0Uhkm"
   },
   "outputs": [],
   "source": [
    "# Tensor board [tensorboard --logdir=./runs]\n",
    "save_output = './Output'\n",
    "save_path = save_output + '/pytorch_fin_32lr1.pt'\n",
    "writer = SummaryWriter('project_pytorch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 888
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 30045,
     "status": "ok",
     "timestamp": 1589731339032,
     "user": {
      "displayName": "Hoshi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgvJ9tk-7YVwMuT4roRhSvIVbF7D-gcIePVxYIukw=s64",
      "userId": "16228246563220513239"
     },
     "user_tz": -480
    },
    "id": "TS_kyesv3eaX",
    "outputId": "6c19f2ed-feae-459f-f3c2-5e20fa90c700"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model value saved to ==> ./Output/pytorch_fin_32lr1.ptv\n",
      "Model saved to ==> ./Output/pytorch_fin_32lr1.pt_latest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:402: UserWarning: Couldn't retrieve source code for container of type LogisticReg. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Step [100/850], Train Loss: 0.095665, Train Acc: 0.141667, Train F1: 0.005849, Valid Loss: 0.629228, Valid Acc: 0.151917,  Valid F1: 0.044879\n",
      "Model average saved to ==> ./Output/pytorch_fin_32lr1.pta\n",
      "Model saved to ==> ./Output/pytorch_fin_32lr1.pt\n",
      "Model value saved to ==> ./Output/pytorch_fin_32lr1.ptv\n",
      "Model saved to ==> ./Output/pytorch_fin_32lr1.pt_latest\n",
      "Epoch [3/10], Step [200/850], Train Loss: 0.166457, Train Acc: 0.146875, Train F1: 0.012579, Valid Loss: 0.544109, Valid Acc: 0.151917,  Valid F1: 0.043199\n",
      "Model average saved to ==> ./Output/pytorch_fin_32lr1.pta\n",
      "Model saved to ==> ./Output/pytorch_fin_32lr1.pt\n",
      "Model value saved to ==> ./Output/pytorch_fin_32lr1.ptv\n",
      "Model saved to ==> ./Output/pytorch_fin_32lr1.pt_latest\n",
      "Epoch [4/10], Step [300/850], Train Loss: 0.233795, Train Acc: 0.170139, Train F1: 0.031641, Valid Loss: 0.502339, Valid Acc: 0.169617,  Valid F1: 0.085009\n",
      "Model average saved to ==> ./Output/pytorch_fin_32lr1.pta\n",
      "Model saved to ==> ./Output/pytorch_fin_32lr1.pt\n",
      "Model value saved to ==> ./Output/pytorch_fin_32lr1.ptv\n",
      "Model saved to ==> ./Output/pytorch_fin_32lr1.pt_latest\n",
      "Epoch [5/10], Step [400/850], Train Loss: 0.291448, Train Acc: 0.270313, Train F1: 0.173994, Valid Loss: 0.476366, Valid Acc: 0.321534,  Valid F1: 0.375093\n",
      "Model average saved to ==> ./Output/pytorch_fin_32lr1.pta\n",
      "Model saved to ==> ./Output/pytorch_fin_32lr1.pt\n",
      "Model value saved to ==> ./Output/pytorch_fin_32lr1.ptv\n",
      "Model saved to ==> ./Output/pytorch_fin_32lr1.pt_latest\n",
      "Epoch [6/10], Step [500/850], Train Loss: 0.349313, Train Acc: 0.467083, Train F1: 0.406007, Valid Loss: 0.470072, Valid Acc: 0.533923,  Valid F1: 0.597912\n",
      "Model average saved to ==> ./Output/pytorch_fin_32lr1.pta\n",
      "Model saved to ==> ./Output/pytorch_fin_32lr1.pt\n",
      "Model value saved to ==> ./Output/pytorch_fin_32lr1.ptv\n",
      "Model saved to ==> ./Output/pytorch_fin_32lr1.pt_latest\n",
      "Model value saved to ==> ./Output/pytorch_fin_32lr1.ptv\n",
      "Model saved to ==> ./Output/pytorch_fin_32lr1.pt_latest\n",
      "Epoch [8/10], Step [600/850], Train Loss: 0.022146, Train Acc: 0.725000, Train F1: 0.036810, Valid Loss: 0.454186, Valid Acc: 0.675516,  Valid F1: 0.705525\n",
      "Model average saved to ==> ./Output/pytorch_fin_32lr1.pta\n",
      "Model saved to ==> ./Output/pytorch_fin_32lr1.pt\n",
      "Model value saved to ==> ./Output/pytorch_fin_32lr1.ptv\n",
      "Model saved to ==> ./Output/pytorch_fin_32lr1.pt_latest\n",
      "Epoch [9/10], Step [700/850], Train Loss: 0.089602, Train Acc: 0.740625, Train F1: 0.146301, Valid Loss: 0.449520, Valid Acc: 0.734513,  Valid F1: 0.726527\n",
      "Model average saved to ==> ./Output/pytorch_fin_32lr1.pta\n",
      "Model saved to ==> ./Output/pytorch_fin_32lr1.pt\n",
      "Model value saved to ==> ./Output/pytorch_fin_32lr1.ptv\n",
      "Model saved to ==> ./Output/pytorch_fin_32lr1.pt_latest\n",
      "Epoch [10/10], Step [800/850], Train Loss: 0.156391, Train Acc: 0.781250, Train F1: 0.264099, Valid Loss: 0.435804, Valid Acc: 0.764012,  Valid F1: 0.756794\n",
      "Model average saved to ==> ./Output/pytorch_fin_32lr1.pta\n",
      "Model saved to ==> ./Output/pytorch_fin_32lr1.pt\n",
      "Model value saved to ==> ./Output/pytorch_fin_32lr1.ptv\n",
      "Model saved to ==> ./Output/pytorch_fin_32lr1.pt_latest\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# Setting of the training model\n",
    "num_epochs = 10\n",
    "eval_every = 100\n",
    "total_step = len(train_loader)*num_epochs\n",
    "best_val_loss = None\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.002)\n",
    "model = model.to(device)\n",
    "\n",
    "TRAIN(model, train_loader, valid_loader, num_epochs, eval_every, total_step, criterion, optimizer, best_val_loss, device, save_path)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GUdPlFCqUsMM"
   },
   "source": [
    "### **Load Model to Continue Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 864,
     "status": "ok",
     "timestamp": 1589731735613,
     "user": {
      "displayName": "Hoshi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgvJ9tk-7YVwMuT4roRhSvIVbF7D-gcIePVxYIukw=s64",
      "userId": "16228246563220513239"
     },
     "user_tz": -480
    },
    "id": "-3ka52IFUrtQ",
    "outputId": "8c19e471-09a9-40c8-d993-39a34c09daed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from <== ./Output/pytorch_fin_32lr2.pt\n"
     ]
    }
   ],
   "source": [
    "# Load model (value will just be replaced after loading)\n",
    "device = 'cuda'\n",
    "\n",
    "load_model = LogisticReg(15, 1).to(device)\n",
    "load_optimizer = optim.Adam(load_model.parameters(), lr=0.002)\n",
    "load_save_path = save_output + '/pytorch_fin_32lr2.pt'\n",
    "load_save_path2 = load_save_path + 'v'\n",
    "load_save_path3 = load_save_path + 'a'\n",
    "load_best_val_loss, latest, load_model, load_optimizer = load_checkpoint(load_model, load_optimizer, load_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 63214,
     "status": "ok",
     "timestamp": 1589732298636,
     "user": {
      "displayName": "Hoshi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgvJ9tk-7YVwMuT4roRhSvIVbF7D-gcIePVxYIukw=s64",
      "userId": "16228246563220513239"
     },
     "user_tz": -480
    },
    "id": "3zbtwMkcVgab",
    "outputId": "677eec20-f5e0-4893-ad05-3e1534c84717"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model value loaded from <== ./Output/pytorch_fin_32lr2.ptv\n",
      "Model average loaded from <== ./Output/pytorch_fin_32lr2.pta\n",
      "Epoch [1/10], Step [22/850], Train Loss: 0.347804, Train Acc: 0.823864, Train F1: 0.822800, Valid Loss: 0.381039, Valid Acc: 0.808260,  Valid F1: 0.804538\n",
      "Model average saved to ==> ./Output/pytorch_fin_32lr2.pta\n",
      "Model saved to ==> ./Output/pytorch_fin_32lr2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:402: UserWarning: Couldn't retrieve source code for container of type LogisticReg. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [44/850], Train Loss: 0.420360, Train Acc: 0.789773, Train F1: 0.782088, Valid Loss: 0.380012, Valid Acc: 0.806785,  Valid F1: 0.808350\n",
      "Model average saved to ==> ./Output/pytorch_fin_32lr2.pta\n",
      "Model saved to ==> ./Output/pytorch_fin_32lr2.pt\n",
      "Epoch [1/10], Step [66/850], Train Loss: 0.421744, Train Acc: 0.815341, Train F1: 0.807158, Valid Loss: 0.413688, Valid Acc: 0.797935,  Valid F1: 0.779952\n",
      "Model average saved to ==> ./Output/pytorch_fin_32lr2.pta\n",
      "Model value saved to ==> ./Output/pytorch_fin_32lr2.ptv\n",
      "Model saved to ==> ./Output/pytorch_fin_32lr2.pt_latest\n",
      "Epoch [2/10], Step [88/850], Train Loss: 0.060660, Train Acc: 0.770833, Train F1: 0.104406, Valid Loss: 0.379546, Valid Acc: 0.796460,  Valid F1: 0.807681\n",
      "Model average saved to ==> ./Output/pytorch_fin_32lr2.pta\n",
      "Model saved to ==> ./Output/pytorch_fin_32lr2.pt\n",
      "Epoch [2/10], Step [110/850], Train Loss: 0.407056, Train Acc: 0.799716, Train F1: 0.798466, Valid Loss: 0.406755, Valid Acc: 0.794985,  Valid F1: 0.781692\n",
      "Model average saved to ==> ./Output/pytorch_fin_32lr2.pta\n",
      "Epoch [2/10], Step [132/850], Train Loss: 0.352896, Train Acc: 0.805398, Train F1: 0.807860, Valid Loss: 0.390063, Valid Acc: 0.800885,  Valid F1: 0.796801\n",
      "Model average saved to ==> ./Output/pytorch_fin_32lr2.pta\n",
      "Epoch [2/10], Step [154/850], Train Loss: 0.419398, Train Acc: 0.792614, Train F1: 0.785507, Valid Loss: 0.378883, Valid Acc: 0.800885,  Valid F1: 0.808099\n",
      "Model average saved to ==> ./Output/pytorch_fin_32lr2.pta\n",
      "Model saved to ==> ./Output/pytorch_fin_32lr2.pt\n",
      "Model value saved to ==> ./Output/pytorch_fin_32lr2.ptv\n",
      "Model saved to ==> ./Output/pytorch_fin_32lr2.pt_latest\n",
      "Epoch [3/10], Step [176/850], Train Loss: 0.114281, Train Acc: 0.802083, Train F1: 0.218546, Valid Loss: 0.389245, Valid Acc: 0.797935,  Valid F1: 0.793981\n",
      "Model average saved to ==> ./Output/pytorch_fin_32lr2.pta\n",
      "Epoch [3/10], Step [198/850], Train Loss: 0.389772, Train Acc: 0.798295, Train F1: 0.794895, Valid Loss: 0.386039, Valid Acc: 0.803835,  Valid F1: 0.790845\n",
      "Model average saved to ==> ./Output/pytorch_fin_32lr2.pta\n",
      "Epoch [3/10], Step [220/850], Train Loss: 0.416833, Train Acc: 0.778409, Train F1: 0.774526, Valid Loss: 0.394398, Valid Acc: 0.797935,  Valid F1: 0.796911\n",
      "Model average saved to ==> ./Output/pytorch_fin_32lr2.pta\n",
      "Epoch [3/10], Step [242/850], Train Loss: 0.386136, Train Acc: 0.828125, Train F1: 0.819040, Valid Loss: 0.392086, Valid Acc: 0.794985,  Valid F1: 0.806280\n",
      "Model average saved to ==> ./Output/pytorch_fin_32lr2.pta\n",
      "Model value saved to ==> ./Output/pytorch_fin_32lr2.ptv\n",
      "Model saved to ==> ./Output/pytorch_fin_32lr2.pt_latest\n",
      "Epoch [4/10], Step [264/850], Train Loss: 0.164227, Train Acc: 0.788194, Train F1: 0.319699, Valid Loss: 0.400503, Valid Acc: 0.799410,  Valid F1: 0.801126\n",
      "Model average saved to ==> ./Output/pytorch_fin_32lr2.pta\n",
      "Epoch [4/10], Step [286/850], Train Loss: 0.418262, Train Acc: 0.792614, Train F1: 0.788336, Valid Loss: 0.392845, Valid Acc: 0.797935,  Valid F1: 0.809645\n",
      "Model average saved to ==> ./Output/pytorch_fin_32lr2.pta\n",
      "Epoch [4/10], Step [308/850], Train Loss: 0.380339, Train Acc: 0.791193, Train F1: 0.796553, Valid Loss: 0.389208, Valid Acc: 0.799410,  Valid F1: 0.794114\n",
      "Model average saved to ==> ./Output/pytorch_fin_32lr2.pta\n",
      "Epoch [4/10], Step [330/850], Train Loss: 0.384185, Train Acc: 0.805398, Train F1: 0.805058, Valid Loss: 0.393289, Valid Acc: 0.803835,  Valid F1: 0.798665\n",
      "Model average saved to ==> ./Output/pytorch_fin_32lr2.pta\n",
      "Model value saved to ==> ./Output/pytorch_fin_32lr2.ptv\n",
      "Model saved to ==> ./Output/pytorch_fin_32lr2.pt_latest\n",
      "Epoch [5/10], Step [352/850], Train Loss: 0.203943, Train Acc: 0.820312, Train F1: 0.445577, Valid Loss: 0.380429, Valid Acc: 0.802360,  Valid F1: 0.803356\n",
      "Model average saved to ==> ./Output/pytorch_fin_32lr2.pta\n",
      "Epoch [5/10], Step [374/850], Train Loss: 0.424799, Train Acc: 0.794034, Train F1: 0.786844, Valid Loss: 0.379981, Valid Acc: 0.796460,  Valid F1: 0.810385\n",
      "Model average saved to ==> ./Output/pytorch_fin_32lr2.pta\n",
      "Epoch [5/10], Step [396/850], Train Loss: 0.375180, Train Acc: 0.802557, Train F1: 0.798736, Valid Loss: 0.390852, Valid Acc: 0.800885,  Valid F1: 0.803401\n",
      "Model average saved to ==> ./Output/pytorch_fin_32lr2.pta\n",
      "Epoch [5/10], Step [418/850], Train Loss: 0.398307, Train Acc: 0.792614, Train F1: 0.795672, Valid Loss: 0.406702, Valid Acc: 0.797935,  Valid F1: 0.785205\n",
      "Model average saved to ==> ./Output/pytorch_fin_32lr2.pta\n",
      "Model value saved to ==> ./Output/pytorch_fin_32lr2.ptv\n",
      "Model saved to ==> ./Output/pytorch_fin_32lr2.pt_latest\n",
      "Epoch [6/10], Step [440/850], Train Loss: 0.266050, Train Acc: 0.791667, Train F1: 0.540007, Valid Loss: 0.402748, Valid Acc: 0.802360,  Valid F1: 0.787303\n",
      "Model average saved to ==> ./Output/pytorch_fin_32lr2.pta\n",
      "Epoch [6/10], Step [462/850], Train Loss: 0.409391, Train Acc: 0.798295, Train F1: 0.793299, Valid Loss: 0.403334, Valid Acc: 0.802360,  Valid F1: 0.791232\n",
      "Model average saved to ==> ./Output/pytorch_fin_32lr2.pta\n",
      "Epoch [6/10], Step [484/850], Train Loss: 0.385493, Train Acc: 0.801136, Train F1: 0.800515, Valid Loss: 0.379828, Valid Acc: 0.800885,  Valid F1: 0.811849\n",
      "Model average saved to ==> ./Output/pytorch_fin_32lr2.pta\n",
      "Epoch [6/10], Step [506/850], Train Loss: 0.391825, Train Acc: 0.811080, Train F1: 0.803852, Valid Loss: 0.379714, Valid Acc: 0.800885,  Valid F1: 0.808245\n",
      "Model average saved to ==> ./Output/pytorch_fin_32lr2.pta\n",
      "Model value saved to ==> ./Output/pytorch_fin_32lr2.ptv\n",
      "Model saved to ==> ./Output/pytorch_fin_32lr2.pt_latest\n",
      "Epoch [7/10], Step [528/850], Train Loss: 0.291919, Train Acc: 0.840278, Train F1: 0.685969, Valid Loss: 0.377869, Valid Acc: 0.802360,  Valid F1: 0.809391\n",
      "Model average saved to ==> ./Output/pytorch_fin_32lr2.pta\n",
      "Model saved to ==> ./Output/pytorch_fin_32lr2.pt\n",
      "Epoch [7/10], Step [550/850], Train Loss: 0.396513, Train Acc: 0.803977, Train F1: 0.800314, Valid Loss: 0.380601, Valid Acc: 0.800885,  Valid F1: 0.799088\n",
      "Model average saved to ==> ./Output/pytorch_fin_32lr2.pta\n",
      "Epoch [7/10], Step [572/850], Train Loss: 0.384245, Train Acc: 0.792614, Train F1: 0.786920, Valid Loss: 0.390982, Valid Acc: 0.800885,  Valid F1: 0.792003\n",
      "Model average saved to ==> ./Output/pytorch_fin_32lr2.pta\n",
      "Epoch [7/10], Step [594/850], Train Loss: 0.432552, Train Acc: 0.769886, Train F1: 0.766814, Valid Loss: 0.379530, Valid Acc: 0.797935,  Valid F1: 0.808307\n",
      "Model average saved to ==> ./Output/pytorch_fin_32lr2.pta\n",
      "Model value saved to ==> ./Output/pytorch_fin_32lr2.ptv\n",
      "Model saved to ==> ./Output/pytorch_fin_32lr2.pt_latest\n",
      "Epoch [8/10], Step [616/850], Train Loss: 0.392190, Train Acc: 0.815476, Train F1: 0.772972, Valid Loss: 0.379984, Valid Acc: 0.796460,  Valid F1: 0.806591\n",
      "Model average saved to ==> ./Output/pytorch_fin_32lr2.pta\n",
      "Epoch [8/10], Step [638/850], Train Loss: 0.390621, Train Acc: 0.796875, Train F1: 0.795298, Valid Loss: 0.392899, Valid Acc: 0.793510,  Valid F1: 0.789339\n",
      "Model average saved to ==> ./Output/pytorch_fin_32lr2.pta\n",
      "Epoch [8/10], Step [660/850], Train Loss: 0.386427, Train Acc: 0.776989, Train F1: 0.789233, Valid Loss: 0.391258, Valid Acc: 0.799410,  Valid F1: 0.792557\n",
      "Model average saved to ==> ./Output/pytorch_fin_32lr2.pta\n",
      "Model value saved to ==> ./Output/pytorch_fin_32lr2.ptv\n",
      "Model saved to ==> ./Output/pytorch_fin_32lr2.pt_latest\n",
      "Epoch [9/10], Step [682/850], Train Loss: 0.035962, Train Acc: 0.765625, Train F1: 0.070961, Valid Loss: 0.379670, Valid Acc: 0.802360,  Valid F1: 0.804480\n",
      "Model average saved to ==> ./Output/pytorch_fin_32lr2.pta\n",
      "Epoch [9/10], Step [704/850], Train Loss: 0.402310, Train Acc: 0.798295, Train F1: 0.790370, Valid Loss: 0.384810, Valid Acc: 0.802360,  Valid F1: 0.810156\n",
      "Model average saved to ==> ./Output/pytorch_fin_32lr2.pta\n",
      "Epoch [9/10], Step [726/850], Train Loss: 0.382105, Train Acc: 0.795455, Train F1: 0.796814, Valid Loss: 0.391545, Valid Acc: 0.800885,  Valid F1: 0.801564\n",
      "Model average saved to ==> ./Output/pytorch_fin_32lr2.pta\n",
      "Epoch [9/10], Step [748/850], Train Loss: 0.408800, Train Acc: 0.805398, Train F1: 0.801764, Valid Loss: 0.390994, Valid Acc: 0.802360,  Valid F1: 0.800322\n",
      "Model average saved to ==> ./Output/pytorch_fin_32lr2.pta\n",
      "Model value saved to ==> ./Output/pytorch_fin_32lr2.ptv\n",
      "Model saved to ==> ./Output/pytorch_fin_32lr2.pt_latest\n",
      "Epoch [10/10], Step [770/850], Train Loss: 0.094108, Train Acc: 0.781250, Train F1: 0.175915, Valid Loss: 0.387121, Valid Acc: 0.802360,  Valid F1: 0.802122\n",
      "Model average saved to ==> ./Output/pytorch_fin_32lr2.pta\n",
      "Epoch [10/10], Step [792/850], Train Loss: 0.367419, Train Acc: 0.809659, Train F1: 0.811879, Valid Loss: 0.397795, Valid Acc: 0.802360,  Valid F1: 0.792869\n",
      "Model average saved to ==> ./Output/pytorch_fin_32lr2.pta\n",
      "Epoch [10/10], Step [814/850], Train Loss: 0.365968, Train Acc: 0.818182, Train F1: 0.818127, Valid Loss: 0.378688, Valid Acc: 0.800885,  Valid F1: 0.801573\n",
      "Model average saved to ==> ./Output/pytorch_fin_32lr2.pta\n",
      "Epoch [10/10], Step [836/850], Train Loss: 0.420672, Train Acc: 0.782670, Train F1: 0.776658, Valid Loss: 0.386923, Valid Acc: 0.803835,  Valid F1: 0.796266\n",
      "Model average saved to ==> ./Output/pytorch_fin_32lr2.pta\n",
      "Model value saved to ==> ./Output/pytorch_fin_32lr2.ptv\n",
      "Model saved to ==> ./Output/pytorch_fin_32lr2.pt_latest\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# Load model to continue training\n",
    "load_num_epochs = 10\n",
    "load_eval_every = len(valid_loader)\n",
    "load_total_step = len(train_loader)*load_num_epochs\n",
    "load_criterion = nn.BCELoss()\n",
    "load_model = load_model.to(device)\n",
    "\n",
    "TRAIN(load_model, train_loader, valid_loader, load_num_epochs, load_eval_every, load_total_step, load_criterion, load_optimizer, load_best_val_loss, device, load_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_s4k1KVEVlLW"
   },
   "source": [
    "### **Metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 180
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3719,
     "status": "ok",
     "timestamp": 1589732824861,
     "user": {
      "displayName": "Hoshi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgvJ9tk-7YVwMuT4roRhSvIVbF7D-gcIePVxYIukw=s64",
      "userId": "16228246563220513239"
     },
     "user_tz": -480
    },
    "id": "t0ZLYcbDH-Hp",
    "outputId": "adcd354f-e712-4dee-8c3b-eacf23ed82b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.94      0.91       720\n",
      "         1.0       0.42      0.25      0.31       128\n",
      "\n",
      "    accuracy                           0.83       848\n",
      "   macro avg       0.65      0.59      0.61       848\n",
      "weighted avg       0.81      0.83      0.82       848\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification Report\n",
    "def eval(model, test_loader):\n",
    "    y_test = []\n",
    "    y_pred = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            model.eval()\n",
    "            inputs = inputs.to(device).float()\n",
    "            labels = labels.to(device).float()\n",
    "            outputs = model(inputs)\n",
    "            threshold = torch.tensor([0.285]).cuda()\n",
    "            pred = (outputs>threshold).cuda().int()\n",
    "            y_pred.append(pred.item())\n",
    "            y_test.append(labels.item())\n",
    "\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "\n",
    "eval(load_model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1136,
     "status": "ok",
     "timestamp": 1589732939159,
     "user": {
      "displayName": "Hoshi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgvJ9tk-7YVwMuT4roRhSvIVbF7D-gcIePVxYIukw=s64",
      "userId": "16228246563220513239"
     },
     "user_tz": -480
    },
    "id": "vhOtc6gdVocO",
    "outputId": "a4ea9879-6f76-4303-85f7-66b425798613"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model value loaded from <== ./Output/pytorch_fin_32lr2.ptv\n",
      "Model average loaded from <== ./Output/pytorch_fin_32lr2.pta\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the metrics values\n",
    "train_loss, train_acc, train_f1, train_time, validation_loss, validation_acc, validation_f1, validation_time = load_value(load_save_path2)\n",
    "avg_train_loss, avg_val_loss, avg_train_acc, avg_val_acc, avg_train_f1, avg_val_f1 = load_average(load_save_path3)\n",
    "# len(train_loss) = roundup(len(train_data) / batch_size) * num_epochs = 2712 / 4 * 10\n",
    "# len(validation_loss) = roundup(len(validation_data) / batch_size) * [rounddown(roundup(len(train_data) / batch_size) * num_epochs / eval_every)] = 170 * 67\n",
    "# len(avg_train_loss) = rounddown(roundup(len(train_data) / batch_size) * num_epochs / eval_every) = 67"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1379,
     "status": "ok",
     "timestamp": 1589732940281,
     "user": {
      "displayName": "Hoshi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgvJ9tk-7YVwMuT4roRhSvIVbF7D-gcIePVxYIukw=s64",
      "userId": "16228246563220513239"
     },
     "user_tz": -480
    },
    "id": "CV-0Xx7xVx57",
    "outputId": "e634c06a-34b9-4e29-9be7-6e1efcd441bb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f7f3e36eda0>]"
      ]
     },
     "execution_count": 456,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualization of metrics\n",
    "plt.plot(avg_train_loss)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "XudT5z8CGin7",
    "7kjelSqVds8K",
    "Aue04l85Sg9k",
    "CS1QDZt4TFS5",
    "g3zRq7KNTI8K",
    "hmYI9zOKdNew",
    "NHkqbthUdIQC",
    "q6fpgIcze4o1",
    "GUdPlFCqUsMM",
    "_s4k1KVEVlLW"
   ],
   "name": "project.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
